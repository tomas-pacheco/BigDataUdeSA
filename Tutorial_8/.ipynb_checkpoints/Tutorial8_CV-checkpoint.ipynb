{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m3CnbNMV2Cp"
   },
   "source": [
    "# Tutorial de Big Data (UdeSA) 2025\n",
    "## Tutorial 7 \n",
    "### Cross-validation\n",
    "\n",
    "\n",
    "**Objetivo:** \n",
    "Que se familiaricen con la técnica de K-fold Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoSQOK1iV2Cs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from ISLP import load_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con la base `Auto` de [ISLP](https://islp.readthedocs.io/en/latest/datasets/Auto.html).\n",
    "\n",
    "Tiene información para 392 vehículos. Kilometraje de gasolina, caballos de fuerza El dataset tiene las siguiente variables:\n",
    "- mpg: millas por galón\n",
    "- cylinders: Número de cilindros entre 4 y 8\n",
    "- displacement: Cilindrada o desplazamiento del motor (pulgadas cúbicas)\n",
    "- horsepower: Caballos del motor\n",
    "- weight: Peso del vehículo (libras)\n",
    "- acceleration: Tiempo de aceleración de 0 a 100 km/h (seg.)\n",
    "- year: Año del modelo (módulo 100)\n",
    "- origin: Origen del vehículo (1. Americano, 2. Europeo, 3. Japonés)\n",
    "- name: Nombre del vehículo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = load_data(\"Auto\")\n",
    "\n",
    "# Dimensión de la base\n",
    "print(\"Dimensión del dataframe:\", auto.shape)\n",
    "\n",
    "# Variables e información\n",
    "#print(auto.dtypes)\n",
    "print(auto.info())\n",
    "\n",
    "auto.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay duplicados?\n",
    "print(\"Duplicados:\", auto.duplicated().sum())\n",
    "\n",
    "# Hay valores faltantes?\n",
    "print(\"\\n Missings:\\n\", auto.isnull().sum()) # conteo\n",
    "#print(auto.isnull().mean() * 100) # como porcentaje\n",
    "\n",
    "# No hay duplicados ni missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le cambiamos el formato a la salida de la estadistica descriptiva \n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # prueben con '%.5f', como luce?\n",
    "\n",
    "# Inspección rápida de las variables y sus valores\n",
    "auto.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recordamos que la variable \"origin\" es categorica. \n",
    "# Origin: Origen del vehículo (1. Americano, 2. Europeo, 3. Japonés)\n",
    "auto[\"origin\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos dummies (variables categóricas binarias) con la función de pandas [get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_dummies = pd.get_dummies(auto['origin'], prefix='origin')\n",
    "\n",
    "# Concatenamos las nuevas variables con el df original\n",
    "auto_d = pd.concat([auto, origin_dummies], axis=1)\n",
    "auto_d.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a trabajar con `mpg` como **variable dependiente** y `horsepower` como **predictor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fRHNPS6V2Ct"
   },
   "outputs": [],
   "source": [
    "# Guardo los vectores de variable dependiente y de variable independiente respectivamente:\n",
    "y = auto_d['mpg']\n",
    "X = auto_d['horsepower']\n",
    "X = np.array(X).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestras aleatorias de Entrenamiento (train) y Testeo (test)\n",
    "Dividimos la base de entrenamiento y testeo de manera aleatorea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parto la base en dos y transformo el vector x: \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre chequear que la base de entrenamiento (train) y de testeo (test) sean realmente aleatorias. Una forma es mirar la estadística descriptiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadisticas_x_train = pd.Series(x_train.flatten()).describe()\n",
    "estadisticas_x_test = pd.Series(x_test.flatten()).describe()\n",
    "estadisticas_y_train = y_train.describe()\n",
    "estadisticas_y_test = y_test.describe()\n",
    "\n",
    "estadisticas = pd.DataFrame({\n",
    "    'x_train': estadisticas_x_train,\n",
    "    'x_test': estadisticas_x_test,\n",
    "    'y_train': estadisticas_y_train,\n",
    "    'y_test': estadisticas_y_test\n",
    "})\n",
    "\n",
    "print(estadisticas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para Probar: Que pasa con la estdistica descriptiva cuando cambian la opcion de `random_state`?\n",
    "\n",
    "Otra alternativas es hacer una tabla de diferencia de medias (t-test) entre el grupo de entrenamiento y de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula los estadísticos\n",
    "estadisticos = pd.DataFrame({\n",
    "    'N train': [x_train.shape[0], y_train.shape[0]],\n",
    "    'Mean train': [x_train.mean(), y_train.mean()],\n",
    "    'sd train': [x_train.std(), y_train.std()],\n",
    "    'N test': [x_test.shape[0], y_test.shape[0]],\n",
    "    'Mean test': [x_test.mean(), y_test.mean()],\n",
    "    'sd test': [x_test.std(), y_test.std()],\n",
    "})\n",
    "\n",
    "# Calcula el t-test y p-value\n",
    "t_test_x = stats.ttest_ind(x_train.flatten(), x_test.flatten())\n",
    "t_test_y = stats.ttest_ind(y_train, y_test)\n",
    "\n",
    "estadisticos['t-test'] = [t_test_x.statistic, t_test_y.statistic]\n",
    "estadisticos['p-value'] = [t_test_x.pvalue, t_test_y.pvalue]\n",
    "\n",
    "# Define las variables como índice\n",
    "estadisticos.index = ['horsepower', 'mpg']\n",
    "\n",
    "# Exporta a Excel\n",
    "estadisticos.to_excel('estadisticos.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enfoque de Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión lineal\n",
    "lreg=LinearRegression()\n",
    "\n",
    "# Estimación del modelo con base de entrenamiento\n",
    "lreg.fit(x_train,y_train)\n",
    "print(\"Coeficiente:\", lreg.coef_) #pendiente\n",
    "\n",
    "# Predicción de 'y' con base de testeo (y sombrerito)\n",
    "y_pred_lreg_train=lreg.predict(x_train)\n",
    "y_pred_lreg=lreg.predict(x_test)\n",
    "\n",
    "# Evaluación del modelo (model assesment)\n",
    "print(\"R2 afuera de la muestra:\", round(r2_score(y_test,y_pred_lreg),2))\n",
    "print(\"R2 adentro de la muestra:\", round(r2_score(y_train,y_pred_lreg_train),2))\n",
    "\n",
    "# Error Cuadrático Medio (MSE de testeo)\n",
    "mse_test_l = mean_squared_error(y_test, y_pred_lreg)\n",
    "mse_train_l = mean_squared_error(y_train, y_pred_lreg_train)\n",
    "\n",
    "print('Error cuadrático medio (test):', round(mse_test_l, 2))\n",
    "print('Error cuadrático medio (train):', round(mse_train_l, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos en la muestra de testeo, la predicción de regresión lineal con un scatter plot\n",
    "plt.plot(x_test, y_test, 'o', alpha=0.7)\n",
    "plt.plot(x_test, y_pred_lreg, color=\"red\")\n",
    "plt.xlabel('Caballos del motor (horsepower)')\n",
    "plt.ylabel('Millas por galón (mpg)')\n",
    "plt.title('Evaluación del modelo de regresión lineal  (d=1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresiónes Polinómicas\n",
    "Implican una transformación polinómica de las $X$, para luego implementar la regresión por MCO (Mínimos Cuadrados Ordinarios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "roKZmBmrV2Cu"
   },
   "outputs": [],
   "source": [
    "# Veamos un modelo cuadrático:\n",
    "poly = PolynomialFeatures(degree = 2, include_bias=False) \n",
    "# Recordar setear include_bias=False dado que en la regresión lineal -con LinearRegression- se incluirá la  \n",
    "#  constante (esto suma una columna de 1s)\n",
    "\n",
    "# Transformamos el vector columna en una matriz para tener en cuenta el grado del polinomio de interés\n",
    "print('X antes de la transformación:\\n', x_train[:5,])\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_test_poly = poly.fit_transform(x_test)  \n",
    "np.set_printoptions(suppress = True) # evita que el print salga con notación científica\n",
    "print('X luego de la transformación:\\n', x_train_poly[:5,])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos el modelo\n",
    "model = LinearRegression().fit(x_train_poly, y_train) \n",
    "print('\\nIntercepto:', model.intercept_)\n",
    "print('Coeficientes:', model.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el Error Cuadrático Medio\n",
    "y_pred_poly = model.predict(x_test_poly)\n",
    "mse_test_d2 = mean_squared_error(y_test, y_pred_poly)\n",
    "print('Error cuadrático medio (test):', mse_test_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarea para la casa: R2 y MSE testeo y train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0v8qlN3V2Cv"
   },
   "outputs": [],
   "source": [
    "# Creamos un nuevo vector de X y aplicamos las transformaciones\n",
    "X_seq = np.linspace(x_test.min(), x_test.max()).reshape(-1,1) \n",
    "print(X_seq[:5,])\n",
    "# Valores entre el minimo y el maximo de X. \n",
    "# linspace por default crea 50 valores\n",
    "# Aplicamos las transformaciones polinomicas\n",
    "X_seq_poly = poly.fit_transform(X_seq) \n",
    "print(X_seq_poly[:5,])\n",
    "\n",
    "# Gráfico en la base de entrenamiento para selecciónar el modelo (Model Selection)\n",
    "plt.figure()\n",
    "plt.scatter(x_test, y_test, alpha=0.7)\n",
    "plt.plot(X_seq, model.predict(X_seq_poly),color=\"red\")\n",
    "plt.xlabel('Caballos del motor (horsepower)')\n",
    "plt.ylabel('Millas por galón (mpg)')\n",
    "plt.title(\"Evaluación del modelo de regresión cuadrático  (d=2)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGeVHCwAV2Cv"
   },
   "outputs": [],
   "source": [
    "# Veamos un modelo cúbico:\n",
    "poly = PolynomialFeatures(degree = 3, include_bias=False) \n",
    "\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_test_poly = poly.fit_transform(x_test)  \n",
    "  \n",
    "model = LinearRegression().fit(x_train_poly, y_train) \n",
    "y_pred_poly = model.predict(x_test_poly)\n",
    "\n",
    "mse_test_d3 = mean_squared_error(y_test, y_pred_poly)\n",
    "\n",
    "print('\\nIntercepto:', model.intercept_)\n",
    "print('Coeficientes:', model.coef_)\n",
    "print('Error cuadrático medio (test):', mse_test_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori, viendo el ECM, parecería que la regresión polinomial de grado 2 es la que mejor funciona "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0v8qlN3V2Cv"
   },
   "outputs": [],
   "source": [
    "# Creamos un nuevo vector de X y aplicamos las transformaciones\n",
    "X_seq = np.linspace(x_test.min(), x_test.max()).reshape(-1,1) \n",
    "print(X_seq[:5,])\n",
    "# Valores entre el minimo y el maximo de X. \n",
    "# linspace por default crea 50 valores\n",
    "# Aplicamos las transformaciones polinomicas\n",
    "X_seq_poly = poly.fit_transform(X_seq) \n",
    "print(X_seq_poly[:5,])\n",
    "\n",
    "# Gráfico en la base de entrenamiento para selecciónar el modelo (Model Selection)\n",
    "plt.figure()\n",
    "plt.scatter(x_test, y_test, alpha=0.7)\n",
    "plt.plot(X_seq, model.predict(X_seq_poly),color=\"red\")\n",
    "plt.xlabel('Caballos del motor (horsepower)')\n",
    "plt.ylabel('Millas por galón (mpg)')\n",
    "plt.title(\"Evaluación del modelo de regresión cúbico (d=3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hacer este grafico de y_predic y y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enfoque de validación con una nueva participación\n",
    "Ahora supongamos que cambiamos la muestra de entrenamienta y de testeo. Repetimos la selección y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zMPx8mCV2Cx"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 50)\n",
    "\n",
    "# Qué error esperarían que obtengamos esta vez?\n",
    "poly = PolynomialFeatures(degree = 2, include_bias=False) \n",
    "\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_test_poly = poly.fit_transform(x_test)  \n",
    "  \n",
    "model = LinearRegression().fit(x_train_poly, y_train) \n",
    "y_pred_poly = model.predict(x_test_poly)\n",
    "\n",
    "mse_test_d2_ = mean_squared_error(y_test, y_pred_poly)\n",
    "\n",
    "print('\\nIntercepto:', model.intercept_)\n",
    "print('Coeficientes:', model.coef_)\n",
    "print('Error cuadrático medio (test):', mse_test_d2_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Funciones: DocString, repaso\n",
    "Cómo podemos repetir el código sin escribirlo por tercera vez?\n",
    "\n",
    "Podemos hacer que nuestro código funcione para otros grados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kvzk8UGzV2Cx"
   },
   "outputs": [],
   "source": [
    "def transf_reg_poly(grado, x_train, x_test, y_train, y_test):\n",
    "    '''\n",
    "    La función realiza una transformación polinomial y luego corre una regresión lineal polinómica\n",
    "    Input:\n",
    "        grado\n",
    "        x_train, x_test, y_train, y_test\n",
    "    Output:\n",
    "        modelo, ecm\n",
    "    '''\n",
    "    poly = PolynomialFeatures(degree = grado, include_bias=False) \n",
    "\n",
    "    x_train_poly = poly.fit_transform(x_train)\n",
    "    x_test_poly = poly.fit_transform(x_test)  \n",
    "  \n",
    "    model = LinearRegression().fit(x_train_poly, y_train) \n",
    "    y_pred_poly = model.predict(x_test_poly)\n",
    "    \n",
    "    mse_test = mean_squared_error(y_test, y_pred_poly)\n",
    "    return model, mse_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbegRYh6V2Cy"
   },
   "outputs": [],
   "source": [
    "mse_test_1_ = transf_reg_poly(1, x_train, x_test, y_train, y_test)[1]\n",
    "mse_test_2b_ = transf_reg_poly(2, x_train, x_test, y_train, y_test)[1]\n",
    "mse_test_3b_ = transf_reg_poly(3, x_train, x_test, y_train, y_test)[1]\n",
    "mse_test_4b_ = transf_reg_poly(4, x_train, x_test, y_train, y_test)[1]\n",
    "mse_test_5b_ = transf_reg_poly(5, x_train, x_test, y_train, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance con la PRIMERA partición de muestras de entrenamiento y testeo\n",
    "print('Regresión lineal:', mse_test_l)\n",
    "print('Grado2:', mse_test_d2)\n",
    "print('Grado3:', mse_test_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BjUojF5V2Cy"
   },
   "outputs": [],
   "source": [
    "# Performance con la SEGUNDA partición de muestras de entrenamiento y testeo\n",
    "print('\\nRegresión lineal:', mse_test_1_)\n",
    "print('Grado2:', mse_test_2b_)\n",
    "print('Grado3:', mse_test_3b_)\n",
    "print('Grado4:', mse_test_4b_)\n",
    "print('Grado5:', mse_test_5b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos concluir que:\n",
    "- la regresión lineal funciona peor (en ambos casos tiene mayor ECM)\n",
    "- introducir un término cuadrático reduce el ECM en ambas muestras.\n",
    "\n",
    "Pero en el caso de introducir un término cúbico, no es obvio si funciona mejor o no...\n",
    "\n",
    "El ECM puede **variar** según qué observaciones quedaron incluidas en los sets de train y test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk05DUbrV2Cz"
   },
   "source": [
    "###  2. K-FOLD CROSS-VALIDATION  \n",
    "\n",
    "Es un **técnica de remuestreo**. Se usa para estimar el error (test) asociado a un método de aprendizaje, para:  \n",
    "- Elegir el nivel de complejidad optimo (Model selection)\n",
    "- Evaluar el error de pronóstico fuera de la muestra (futura, condicional, contra fáctica, etc.) (Model Assesment)\n",
    "\n",
    "Consiste en:\n",
    "- Dividir las observaciones en k folds (pliegues), del mismo tamaño, aleatoriamente. \n",
    "- Ajustar el modelo k veces, cada vez con k-1 folds (distintos cada vez). Computar k veces el error de predicción en el fold reservado. (cada fold se usa k-1 veces como training set y 1 vez como test set).\n",
    "- Estimar el error de predicción, estimación que surge de promediar las K estimaciones obtenidas.\n",
    "\n",
    "Vamos a usar [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) de Scikitlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "#Ilustración de Cross-Validation\n",
    "display(Image(url=\"https://global.discourse-cdn.com/dlai/optimized/3X/a/3/a3ed2de61c2b4fa00f1b7e939753e1a7e181afb0_2_690x476.png\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = auto['mpg']\n",
    "X = auto['horsepower']\n",
    "X = np.array(X).reshape((-1, 1))\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "ecms = pd.DataFrame(columns=[\"grado\", \"particion\", \"ecm\"])\n",
    "ecms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo usual es usar K=5 o K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X), type(y))\n",
    "print(X.shape, y.shape)\n",
    "#print(X.flatten(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktqljY-fV2Cz"
   },
   "outputs": [],
   "source": [
    "K = 10\n",
    "\n",
    "for grado in range(2, 10):   \n",
    "\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=100)\n",
    "    \n",
    "    # El método kf.split aplicado a X nos da los conjuntos de índices que necesitamos para\n",
    "    # partir nuestros conjunto de datos en training y testing en cada iteración.\n",
    "    #  OXXXX\n",
    "    #  XOXXX\n",
    "    #  XXOXX\n",
    "    #  XXXOX\n",
    "    #  XXXXO\n",
    "    \n",
    "    for i, (train_index, val_index) in enumerate(kf.split(X)):   \n",
    "        x_train, x_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "        #print(i, x_train.shape[0])\n",
    "        \n",
    "        ecm = transf_reg_poly(grado, x_train, x_val, y_train, y_val)[1]\n",
    "            \n",
    "        df_i = pd.DataFrame({\"grado\": grado, \"particion\": i, \"ecm\": ecm}, index=[0])\n",
    "        ecms = pd.concat([ecms, df_i])\n",
    "    \n",
    "mses = ecms.astype({\"grado\":int, \"particion\":int})\n",
    "mses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una corrección para no contaminar los datos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 50)\n",
    "print(type(X_train), type(y_train))\n",
    "print(X_train.shape, y_train.shape)\n",
    "#print(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktqljY-fV2Cz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ecms = pd.DataFrame(columns=[\"grado\", \"particion\", \"ecm\"])\n",
    "ecms\n",
    "\n",
    "K = 10\n",
    "\n",
    "for grado in range(1, 10):   \n",
    "\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=100)\n",
    "    \n",
    "    # El método kf.split aplicado a X nos da los conjuntos de índices que necesitamos para\n",
    "    # partir nuestros conjunto de datos en training y testing en cada iteración.\n",
    "    #  OXXXX\n",
    "    #  XOXXX\n",
    "    #  XXOXX\n",
    "    #  XXXOX\n",
    "    #  XXXXO\n",
    "    \n",
    "    for i, (train_index2, val_index2) in enumerate(kf.split(X_train)):\n",
    "        X_train_fold, X_val_fold = X_train[train_index2], X_train[val_index2]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index2], y_train.iloc[val_index2]\n",
    "        #print(i, X_train_fold.shape[0])\n",
    "        \n",
    "        ecm = transf_reg_poly(grado, X_train_fold, X_val_fold, y_train_fold, y_val_fold)[1]\n",
    "            \n",
    "        df_i = pd.DataFrame({\"grado\": grado, \"particion\": i, \"ecm\": ecm}, index=[0])\n",
    "        ecms = pd.concat([ecms, df_i])\n",
    "    \n",
    "ecms = ecms.astype({\"grado\":int, \"particion\":int})\n",
    "ecms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cómo elegir el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThaTPH93V2C0"
   },
   "outputs": [],
   "source": [
    "# Una opción: visualizar los ECMs en un boxplot\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "ss = sns.boxplot(data=ecms, x=\"grado\", y=\"ecm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecms.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BJJix54xV2C0"
   },
   "outputs": [],
   "source": [
    "# Una opción para ver el mejor modelo sería sacar el error promedio para cada grado:\n",
    "ecms_avg = ecms.groupby('grado').agg({'ecm':'mean'})\n",
    "ecms_avg.reset_index(inplace = True)\n",
    "ecms_avg.astype({\"grado\":int})\n",
    "ecms_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea para la casa: hacer grafico de puntos conectados como el libro (slide 25 panel de la izquierda-clase13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr5xl6PxV2C0"
   },
   "outputs": [],
   "source": [
    "# Función para seleccionar \n",
    "min_ecm = np.Inf\n",
    "grado = None\n",
    "\n",
    "for index, row in ecms_avg.iterrows():\n",
    "    if row['ecm'] < min_ecm:\n",
    "        min_ecm = row['ecm']\n",
    "        grado = row['grado'].astype(int)\n",
    "\n",
    "print('El mínimo error es', round(min_ecm, 2), 'y se da con un polinomio de grado', grado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O14qkQTSV2C0"
   },
   "outputs": [],
   "source": [
    "# Finalmente construimos el modelo polinomial de grado 5 y lo graficamos \n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 50)\n",
    "\n",
    "modelo = transf_reg_poly(grado, x_train, x_test, y_train, y_test)[0]\n",
    "ecm = transf_reg_poly(grado, x_train, x_test, y_train, y_test)[1]\n",
    "        \n",
    "X_seq = np.linspace(X.min(), X.max()).reshape(-1,1)\n",
    "poly = PolynomialFeatures(degree = grado, include_bias=False) \n",
    "X_seq_poly = poly.fit_transform(X_seq)  \n",
    "\n",
    "x_test_poly = poly.fit_transform(x_test)  \n",
    "y_pred_poly = modelo.predict(x_test_poly)\n",
    "ecm_final = mean_squared_error(y_test, y_pred_poly)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(X_seq, modelo.predict(X_seq_poly),color=\"red\")\n",
    "plt.xlabel('Caballos del motor (horsepower)')\n",
    "plt.ylabel('Millas por galón (mpg)')\n",
    "plt.title(\"Polinomio elegido de grado por CV {}\".format(grado))\n",
    "plt.show()\n",
    "\n",
    "ecm_final"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Tutorial 8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
