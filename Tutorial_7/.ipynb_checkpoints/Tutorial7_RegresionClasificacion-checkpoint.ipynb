{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbQnrDd5kPBV"
   },
   "source": [
    "# Tutorial de Big Data (UdeSA) 2025\n",
    "## Tutorial 7 \n",
    "### Clasificacion: Logit, LDA, KNN, QDA & Naive Bayes\n",
    "\n",
    "**Objetivo:** entender la \"diferencia\" entre clasificación y regresión. Utilizar Bayes, análisis de discriminante lineal y KNN. Análisis de la curva ROC.\n",
    "\n",
    "Veremos:\n",
    "- Clasificación\n",
    "- Medidas de precisión\n",
    "- Curva de ROC\n",
    "- Análisis de discriminante lineal (LDA) y cuadrático (QDA)\n",
    "- KNN\n",
    "- Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCC29krdkPBZ"
   },
   "outputs": [],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm     \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "#from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tdJMCuTkPBb"
   },
   "source": [
    "#### Nueva situación: 'y' es una variable cualitativa. ¿Qué hacer? \n",
    "\n",
    "- ¿Por qué en el caso de 'y' cualitativa la regresión linear no es una opción apropiada?\n",
    "\n",
    "1. Puede no haber una forma de transformar una variable cualitativa con más de 2 niveles en una variable cuantitaiva que nos 'sirva' para una regresión lineal: puede que 'y' no tenga un orden. Por ejemplo, si la 'y' hace referencia a enfermedades. ¿Cómo asignarles un valor? Implicaría asumir un orden y también que la diferencia entre las enfermedades es equivalente...\n",
    "\n",
    "2. En el caso binario (2 niveles) podemos transformar la variable a una variable numérica. Por ejemplo: y=1 pobre e y=0 no pobre. Sin embargo, con una regresión  lineal podría ocurrir que generemos predicciones fuera del intervalo [0, 1] y por ende no podremos interpretarlo como probabilidades...\n",
    "\n",
    "Entonces...\n",
    "#### Vamos a clasificar 'y' (variable cualitativa) en base a 'x'\n",
    "\n",
    "- ¿Estamos ante un caso de aprendizaje supervisado o no supervisado? \n",
    "\n",
    "Vamos a trabajar con bases donde tenemos el output esperado. Por lo tanto, nuestros modelos serán casos de aprendizaje supervisado.\n",
    "     \n",
    "- ¿Qué es el clasificador de Bayes? \n",
    "\n",
    "Clasificar según el estado más probable minimiza el riesgo esperado. Por ej: si la probabilidad de que una persona me pague un credito es mayor que 0.5, predigo que pagará el credito. \n",
    "\n",
    "#### Modelos:\n",
    "    \n",
    "1. Regresión logística \n",
    "2. Análisis de discriminante lineal\n",
    "3. KNN\n",
    "\n",
    "Vamos a construir un clasificador con los datos de training. Queremos que funcione bien no solo en el conjunto de entrenamiento sino también en el conjunto de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGRESIÓN LOGÍSTICA CON SCIKIT-LEARN\n",
    "\n",
    "Algoritmo de clasificación que se usa para predecir la probabilidad de una variable dependiente categórica. El modelo logit predice $P(Y=1)$ como una función de $X$. Se modela la probabilidad de una forma tal que los outputs serán valores entre 0 y 1 para cualquier valor de $X$.\n",
    "\n",
    "\n",
    "Ahora utilizaremos la función [LogisticRegression()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "Se pueden proveer muchos parámetros opcionales para esta función:\n",
    "\n",
    "- **fit_intercept**: Boolean que decide si calcular el intercepto (True) o considerarlo igual a cero (False). Por default es True.\n",
    "- **penalty**: Se determina se usar algún tipo de regularización. Posibles valores: ‘l1’, ‘l2’, ‘elasticnet’, None. El valor por defecto es default es ‘l2’, es decir que se aplica regularización.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKjyS79GkPBc"
   },
   "outputs": [],
   "source": [
    "# Creamos un vector de x e y para fines del ejemplo.\n",
    "np.random.seed(25)\n",
    "X = np.random.normal(size=100)\n",
    "print(X)\n",
    "\n",
    "# Recordatorio: para la regresión lineal creamos un vector aleatorio así:\n",
    "# y = 2 + 3*x + np.random.rand(50, 1)\n",
    "# Ahora lo crearemos de la siguiente forma para que tenga más sentido usar una regresión logística\n",
    "y = (X > 0).astype(float) # si no pusiera astype sería un array de True y False\n",
    "\n",
    "# Alteramos los valores de X y sumamos variación con el \"error\"\n",
    "X[X > 0] *= 4\n",
    "X += .5 * np.random.normal(size=100)\n",
    "X = X.reshape((-1, 1)) # para tenerlo como columna\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4I__jLCpkPBd",
    "outputId": "28b640d8-4491-4fc6-e4c1-a64057a16ca7"
   },
   "outputs": [],
   "source": [
    "# Graficamos para ver si nos quedó un vector que 1s y 0s\n",
    "plt.scatter(X, y, color='orange', zorder=20, marker=\"|\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irnHZgZbkPBe",
    "outputId": "5c14ea37-11ca-43fc-fd6a-1ea7430277b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ajustamos el clasificador con el método fit() \n",
    "log_reg = LogisticRegression(penalty=None).fit(X, y)\n",
    "\n",
    "# Predicciones (probabilidad)\n",
    "y_pred_score = log_reg.predict_proba(X)[:,1]   # Por qué seleccionamos la columna 1?\n",
    "\n",
    "# Gráfico de resultados\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(X, y_pred_score, color='red', zorder=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADgZMAw_kPBe",
    "outputId": "140f7389-7777-4563-bbfd-6f8079fe87fd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convertimos las probabilidades en Y con valores 1 o 0 (usando el clasificador de Bayes)\n",
    "y_pred = np.where(y_pred_score > 0.5, 1, y_pred_score)\n",
    "y_pred = np.where(y_pred_score <= 0.5, 0, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(X, y_pred, color='red', zorder=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Nk2FQwEkPBf",
    "outputId": "9525ef11-dbf9-4eef-e61b-3057037ea524",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Equivalente a lo anterior es usar predict() (clasifica en 0s y 1s)\n",
    "y_pred_2 = log_reg.predict(X)\n",
    "print(pd.crosstab(index=y_pred, columns=y_pred_2))\n",
    "\n",
    "# Y graficamos los resultados\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(X, y_pred_2, color='red', zorder=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGRESIÓN LOGÍSTICA CON STATSMODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYIj_a2nkPBf",
    "outputId": "dc43f14e-f668-429c-9717-c1f67c9c4db7"
   },
   "outputs": [],
   "source": [
    "# Podemos repetirlo con statsmodels\n",
    "# Primero agregamos la columna de 1s y hacemos el ajuste\n",
    "X_sm = sm.add_constant(X) \n",
    "logit_model = sm.Logit(y, X_sm)\n",
    "result = logit_model.fit()\n",
    "print(result.summary2()) \n",
    "#También podríamos vn: print(result.summary2().as_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb5paFYmkPBg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_score_sm = result.predict(X_sm)\n",
    "\n",
    "# El método where requiere una condición como primer parámetro, \n",
    "# que cuando es True devuelve el segundo valor y cuando es False devuelve tercero. \n",
    "y_pred_sm = np.where(y_pred_score_sm > 0.5, 1, y_pred_score_sm)\n",
    "y_pred_sm = np.where(y_pred_score_sm <= 0.5, 0, y_pred_sm)\n",
    "\n",
    "print(pd.crosstab(index=y_pred, columns=y_pred_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0jSYKT8kPBg"
   },
   "source": [
    "#### El método predict() de statsmodels, ¿a qué metodo se parece en scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeAbfCsAkPBg"
   },
   "source": [
    "### Medidas de precisión \n",
    "\n",
    "Dependiendo la prioridad del problema seguramente vamos a querer usar diferentes métricas. Scikit learn tiene muchas métricas que pueden explorar en el módulo [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "- Sensitivity o Recall o True Positive Rate: TP rate = TP/P\n",
    "- Specificity o True Negative Rate: 1 - FP rate = TN/N\n",
    "- False Positive Rate o False Alarm Rate: FP rate = FP/N\n",
    "- False Negative Rate: FN rate = FN/P\n",
    "- Precision o Positive Predicted Value: TP/(TP+FP)\n",
    "- Accuracy: (TP+TN)/(P+N)\n",
    "\n",
    "Nota: Cuidado con las traducciones! \"Accuracy\" lo pueden encontrar traducido como \"precisión\" y eso puede generar confusión con la medida \"precision\" (o positive predicted value). Mi sugerencia es traducir \"accuracy\" como \"exactitud\".\n",
    "\n",
    "\n",
    "[Matriz de confusión](https://www.unite.ai/what-is-a-confusion-matrix/)\n",
    "<center>\n",
    "<img src=\"https://www.unite.ai/wp-content/uploads/2019/12/Preventive_Medicine-e1576294312614.png\" width=\"1000\">\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfTtD3wGkPBh",
    "outputId": "cfc2fc2d-aeb5-43f6-9dfa-a87d5403f1f1"
   },
   "outputs": [],
   "source": [
    "matriz_confusion = confusion_matrix(y, y_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(matriz_confusion) \n",
    "print('Accuracy Score:', accuracy_score(y, y_pred))\n",
    "\n",
    "# Nota importante: en Python la matriz de confusión tiene:\n",
    "# en las filas los valores ciertos\n",
    "# y en las columnas los valores predichos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión de sklearn pone en las filas las Y reales y las columnas las Y predichas. Muestra así los valores:\n",
    "\n",
    "                               predicción\n",
    "                         real   tn fp\n",
    "                                fn tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3TW-0AdkPBh",
    "outputId": "4ea0980b-afbc-4ca0-c0a8-d8763a64de05"
   },
   "outputs": [],
   "source": [
    "# Para los casos donde la predición (la y) es binaria podemos usar lo siguiente:\n",
    "tn, fp , fn, tp = confusion_matrix(y, y_pred).ravel()   # Ravel transforma la matriz en un 1D array\n",
    "# equivalente a: [tn, fp] , [fn, tp] = confusion_matrix(y, y_pred_2)\n",
    "\n",
    "print(\"Verdadero 0: \", tn)\n",
    "print(\"Falso 1: \", fp)\n",
    "print(\"Falso 0: \", fn)\n",
    "print(\"Verdadero 1: \", tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# recall: tp / p = tp / (tp + fn)\n",
    "recall = recall_score(y, y_pred)\n",
    "print('Recall: %f' % recall)"
   ]
  },
  {
   "attachments": {
    "roc.JPG": {
     "image/jpeg": "/9j/4AAQSkZJRgABAQEAYABgAAD/4RDmRXhpZgAATU0AKgAAAAgABAE7AAIAAAAJAAAISodpAAQAAAABAAAIVJydAAEAAAASAAAQzOocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZpY3RvcmlhAAAABZADAAIAAAAUAAAQopAEAAIAAAAUAAAQtpKRAAIAAAADNjAAAJKSAAIAAAADNjAAAOocAAcAAAgMAAAIlgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADIwMjM6MTA6MTMgMDA6NDY6MDIAMjAyMzoxMDoxMyAwMDo0NjowMgAAAFYAaQBjAHQAbwByAGkAYQAAAP/hCxtodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIzLTEwLTEzVDAwOjQ2OjAyLjU5NzwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5WaWN0b3JpYTwvcmRmOmxpPjwvcmRmOlNlcT4NCgkJCTwvZGM6Y3JlYXRvcj48L3JkZjpEZXNjcmlwdGlvbj48L3JkZjpSREY+PC94OnhtcG1ldGE+DQogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgIDw/eHBhY2tldCBlbmQ9J3cnPz7/2wBDAAcFBQYFBAcGBQYIBwcIChELCgkJChUPEAwRGBUaGRgVGBcbHichGx0lHRcYIi4iJSgpKywrGiAvMy8qMicqKyr/2wBDAQcICAoJChQLCxQqHBgcKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKir/wAARCAIAAlcDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD6RooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKK87+NvjPV/AngBdW0B4UujeRw5mj3jaQxPH4CuL1PxB8cPD/hV/E95N4bu7CCBbmSJEbf5ZAPTC9j2NK6s32HZ3S7nvFFeS6z8cYtN+D+keK4dOEmqaxmG1sSxK+aCQxJ6lQR9TkDvmsW81X486HobeJr9dCubaGPz59JSP8AexxgZPQDoPRyfrTejafQS1St1PdKK8xuPjbpMXwbTxzHbMzyN9nSxL8/aehQt6DBbPpXKz698drfw6PFzwaK9nsFwdHSEmYRHnpjPTnAfPt2oejafQFqlbqe8UVj+FNbm8R+FbDVbvTrnTJ7mLdLaXMZR4m6EYIBxxkHHIwa4j4m/ErV9D8R6Z4O8D2MN94k1Nd6mf8A1dunPzEZGT8rHngAZ5oldPl6gtVfoen0V4pD4p+LfgrxRpdt40sLTxFpmpSeW0uj27O9ueMnCqDxnPK4IBwa9a/4SDSP7fGh/wBpW39qmPzfsfmDzdnXdt64p20uLrY0aKy08TaJJqd7p0eq2jXthGZbq3Eo3wIADuYdhyPzrM/4WV4K3QAeKNLJuEZ4sXKncq5yf0P5GkM6eis6z8QaRqGiNrFjqVrcaaqs7XccoMYC53Et04wc1X/4TDw4PD39unW7EaVkqL0zr5RIOMBuhOeMUbAbNFZWg+KND8UWzz+HtVtNRjjOHNvKGKH3HUfjWrQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB45+0/wD8kjT/ALCMP/oL15r8QvBniPwr4Y0XVNX8Ua/4h8J3Kwi/svtjoYQQCq4JZdvYEjggDuDX0p4o8J6J4z0gaZ4lsvttmJBKIvNeP5hnByhB7nvVq90PTdR0CTRL60SfTpIPs7wOSQUxgDOc/jnPepSaT73T/AptNrtZr8T5++MEGlWfg/4c+IvC0HmeGdMuAVWPnajFGG73Oxgc969a8R/Enwlb+ALzWF1uxuLeW0fyY0nUvKzKcIFznOTgjHHfpWrpPgTw3onheXw5YaWn9jzFi9nPK86Hd1/1jNgd8Dvz1rmIPgD8N7fUReJ4eDENuEUlzK0YP+6WwR7HIqpLmUo9G2/v3Jj7rjLqv02PAp/DGqw/st2epNBJ5A103pTB4hKeWH+m4frX0XdfFjwnp3w8XxKuqWs8ItleO1jnXzXfHEQXqGzweOOtdm9jaSaebGS2ha0aPyjbmMeWUxjbt6YxxiuBT4CfDdNU+3Dw6hYNuEJuJTFn/c3Yx7dPam222uj/AMrfoJJKzfS/4u51nhLxHD4u8K2Ou2tpc2kN7HvSK6UBwMkZ4JGDjIPcYrxvxbdw+Ef2sNH13XnFvpl/ZeTHdSHCI2xk5PQYOM+gbNe9xRJDEkUKLHGihURRgKB0AHYVleJPCuh+L9LOn+JNOhv7bO5VkyCh9VYYKn3BFJ/EpR6f8MNfC4y6/wDDnM+Kvi94d8M6zpGlws2s3epzCNYdNkSV4wcAMRnHJIwM+vpXF3E0dv8AtkQGd1jEukbU3nG47DwPyNd54W+EPgnwdqQ1HQ9FVL1c7J5pXlaPP93cSF+o5qz4v+GXhLx1dQXXiXSluri3XYkqSvG23OdpKkZH16Z4o2afr+KsG6a9PzueR6BdwX3x0+KU9pKk0R0eVQ6NkEqqKeR7gir/AOzj4I8PXvw9j1y/0u3udSe7mRbiVdzIm3ZtHoMFvzr0/SPhn4Q0C7vLnRtFjs5L21+xz+XLIFeLAG3buwOg5AB755rU8NeF9H8H6MuleHLP7HZK7SCLzXkwzdTlyT+tEUoxs+yX4t/kEm5O/nf8Ej5e1PU9T8DaX4r+Etosjz6hqkSaaeeYJjzz7gIP+BNW/wDFfQZPDusfDbwtBDaT6Zax7VivnMdtPcbhuMhHYkj/AL6PrXvF/wCBfDeqeLrPxPf6Wk2sWShYLkyONgGcfKDtJG48kGpvFHhDQvGel/2d4l06O+tw29AxKsjeqspBB+hpK6Svq01fzsrL/P1G7Nu2zT+97/12PHfA2hajpn7QH2h/+EY0Z3sWjvdH0e6OWG3KuI9oHXaTj69698rlvB/w18KeBGmk8NaUttPONsk7yNJIy9cbmJwPYYrqap7JdierYUUUUhhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUVh3vjfwppt41pqPibR7S5U4aGe/iR1PuC2RQBuUVFa3dvfWqXNlcRXEEgyksLh1YexHBqWgAoorJ17xBHoIsVNjeX899cG3ggs1QuzCN5D99lAAWNj1oA1qK5v/hLL7/oTfEH5Wv8A8fo/4Sy+/wChN8Qfla//AB+gDpKK5v8A4Sy+/wChN8Qfla//AB+j/hLL7/oTfEH5Wv8A8foA6Siub/4Sy+/6E3xB+Vr/APH6P+Esvv8AoTfEH5Wv/wAfoA6Siub/AOEsvv8AoTfEH5Wv/wAfo/4Sy+/6E3xB+Vr/APH6AOkorm/+Esvv+hN8Qfla/wDx+j/hLL7/AKE3xB+Vr/8AH6AOkorm/wDhLL7/AKE3xB+Vr/8AH6P+Esvv+hN8Qfla/wDx+gDpKK5v/hLL7/oTfEH5Wv8A8fo/4Sy+/wChN8Qfla//AB+gDpKK5v8A4Sy+/wChN8Qfla//AB+j/hLL7/oTfEH5Wv8A8foA6Siub/4Sy+/6E3xB+Vr/APH6P+Esvv8AoTfEH5Wv/wAfoA6Siub/AOEsvv8AoTfEH5Wv/wAfo/4Sy+/6E3xB+Vr/APH6AOkorm/+Esvv+hN8Qfla/wDx+j/hLL7/AKE3xB+Vr/8AH6AOkorm/wDhLL7/AKE3xB+Vr/8AH6P+Esvv+hN8Qfla/wDx+gDpKK5v/hLL7/oTfEH5Wv8A8fo/4Sy+/wChN8Qfla//AB+gDpKK5v8A4Sy+/wChN8Qfla//AB+j/hLL7/oTfEH5Wv8A8foA6Siub/4Sy+/6E3xB+Vr/APH6P+Esvv8AoTfEH5Wv/wAfoA6Siub/AOEsvv8AoTfEH5Wv/wAfo/4Sy+/6E3xB+Vr/APH6AOkorm/+Esvv+hN8Qfla/wDx+j/hLL7/AKE3xB+Vr/8AH6AOkorm/wDhLL7/AKE3xB+Vr/8AH6P+Esvv+hN8Qfla/wDx+gDpKK5v/hLL7/oTfEH5Wv8A8fo/4Sy+/wChN8Qfla//AB+gDpKK5v8A4Sy+/wChN8Qfla//AB+j/hLL7/oTfEH5Wv8A8foA6Siub/4Sy+/6E3xB+Vr/APH6P+Esvv8AoTfEH5Wv/wAfoA6Siub/AOEsvv8AoTfEH5Wv/wAfo/4Sy+/6E3xB+Vr/APH6AOkorm/+Esvv+hN8Qfla/wDx+j/hLL7/AKE3xB+Vr/8AH6AOkorm/wDhLL7/AKE3xB+Vr/8AH6P+Esvv+hN8Qfla/wDx+gDpKK5v/hLL7/oTfEH5Wv8A8fo/4Sy+/wChN8Qfla//AB+gDpKK5v8A4Sy+/wChN8Qfla//AB+mQeNkbWrPTb7QtW0+S8l8qN7gQFQxR3G7ZKzAERPg4xkUAdPRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAGb4jtL2/8AC+qWmkzeRfT2ksdvLnGyQqQpz25xzXmGj6v4O0DR7bTNU+HGp2V5DGqTRnQDceY4GGIlVWEmTn5s817DRS6vz/r9R9DgvhtpzW+oa/qNnoVx4f0a/miay064jETBlUiSXyhxHuJXjg/LnHNd7VCy0+4tdU1C6m1Ke5iu2QxW0gGy2CrghMc8nk5q/TEFc34m/wCRn8Hf9hWX/wBIbmrep6Rq15emax8S3enxEACCK2gdQfXLoTz9a5nU9O1XT/G/gxr/AMQXOpxSalOvlTW8MYU/Ybk7sogP9OaAO/ooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiqp1OwViGvbYEHBBlXj9aai3sgLVFYHiHxv4e8MaX9v1bUolhMgjURfvGZj0AVcnsfyrA/4XP4S/van/4LJv8A4muyll+LrR56dKTXdJkucVuzvqK88i+LsWoXU6eH/CfiLVoIdoa4htAikkZwA5B/T+hqb/hZOqf9E88T/wDfhP8A4qtXleLWko29XFP7mxc8TvaK4L/hZOqf9E88T/8AfhP/AIqj/hZOqf8ARPPE/wD34T/4ql/ZmK7L/wACj/mHPE72ivO5fH/i29uoLfQvh3qQZ9xkk1OZbZEAHGCN2c8+nbrnib/hIfiX/wBCNp//AIOF/wDiabyyuvicV6zh/wDJBzo76iuB/wCEh+Jf/Qjaf/4OF/8AiaP+Eh+Jf/Qjaf8A+Dhf/iaX9nVf54f+Bw/+SDnX9I76ivPbjX/ii9tItr4L0uGYqQkkmqq6qfUqAM/TIpk+mfFy8sTEdd8N2MkijdLb20jPH67d2QfTkflVLLmvjqwX/byf/pNw5+yZ6LRXAjwR40wM/Ey9J740uCl/4Qjxn/0Uu+/8FkFT9Uw//QRH7p//ACAcz7fkd7RXBf8ACEeM/wDopd9/4LIKP+EI8Z/9FLvv/BZBR9Uw/wD0ER+6f/yAcz7fkd7RXBf8IR4z/wCil33/AILIKP8AhCPGf/RS77/wWQUfVMP/ANBEfun/APIBzPt+R3tFcF/whHjP/opd9/4LIKP+EI8Z/wDRS77/AMFkFH1TD/8AQRH7p/8AyAcz7fkd7RXBf8IR4z/6KXff+CyCj/hCPGf/AEUu+/8ABZBR9Uw//QRH7p//ACAcz7fkd7RXBf8ACEeM/wDopd9/4LIKP+EI8Z/9FLvv/BZBR9Uw/wD0ER+6f/yAcz7fkd7RXBf8IR4z/wCil33/AILIKP8AhCPGf/RS77/wWQUfVMP/ANBEfun/APIBzPt+R3tFcF/whHjP/opd9/4LIKP+EI8Z/wDRS77/AMFkFH1TD/8AQRH7p/8AyAcz7fkd7RXBf8IR4z/6KXff+CyCj/hCPGf/AEUu+/8ABZBR9Uw//QRH7p//ACAcz7fkd7RXBf8ACEeM/wDopd9/4LIKWw8I+LPt8T3XxAv7qyRytxA2nxwNIAcFQwAIBGfmU56EHvSlhaCV1Xi/lP8A+RDmfY7bzi82yAI+yTZNliCny7hjjk8rxxwc54wed8TR+VqPhBC7SFdXCl3+82LS45OO9dRXN+LP+Qv4T/7DX/trcV55Z0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAQXtnBqNhPZXiF4LiNo5FDFcqRgjI5H4V5n4e+B2hWYvoNft5NQjFyzWVyNTulkaE8hZFVwoZTkZHUYPWvU6KOtw6WMTw34P0TwjHcR6BayW63JVpRJdSzZIzj/AFjNjqelbdFFABXK+Kv+Rx8Ef9hWf/0gua6quV8Vf8jj4I/7Cs//AKQXNAHVUUUUAFFFFABRRRQAUUUUAFFFFABRRXn2v/GDQ7K5j0zwwreJdanmMEVjYn+IA5LPjAUY6jPc9ATXTh8LXxUuWjFv8l6vZLzZLko7nb6lqdlo2mzX+qXMdraQAGSaVsKoJwOfqQK4iL41+E7ne1iNUvIkcp51vp0roSPQ4rG1fw78Q/iNb2emeKY9O0DQpGWW+htJTLPKAQwTnIByB3wDzzgCvV4YIraFYreJIo16IihQPwFd8qODwtNKt+8m76RkrJdLuzu3rs9F6k3lJ6aHnlv8UtW1G0e50n4e+ILiElhE8oSLfjpkE5A/P8aYdX+LWq2UP2Pw7o2jPMwLSXd2ZWiX3Re/T1+menpNFZ/XaEH+7w8fm5S/W34D5X1Z5zH4F8cX8dw+tfES6hkmZsRadaokaIewJ5H16++ean0n4KeB9N0m3tLnR4r+WJcPc3BO+U5yScHH4eld/RSlmuMa5YT5V/dSj/6Sl+IckTkrT4WeCbC9hu7Tw5ZxzwOJI3wx2sDkHk+tdbRRXFWxFau06s3K3dt/mUklsFFFFYjCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACimvKkbIruqtI21ATgscE4HqcAn8DUKRfaFWS6jOGVHFvKqt5TjnORnnOO56cUAGxrtf3y7YCMGJ0w24Nwcg9OOmPx7VYoooAK5vxZ/yF/Cf/AGGv/bW4rpK5vxZ/yF/Cf/Ya/wDbW4oA6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5XxV/yOPgj/ALCs/wD6QXNdVXK+Kv8AkcfBH/YVn/8ASC5oA6qiiigAooooAKKKKACiisjxL4o0rwno82o61dxQJHGzRxtIqvOVGdiAkbmPp71dOnOrNQgrt9BN21Zqu6RRtJIyoigszMcAAdya81m+Jmva9quoaf8ADzw1HqqWN0tu+pz3irbg9zgEFgP9knjn0BzNB8F6r8T9Pg8R/EPVbwafekT2ehWkvlwpCc7C5HLEqc54bB684Hp2iaBpPhvTlsdC0+CxtlwSkKY3HAG5j1ZsAcnJNexKGEwDlGdqtRaW15E+uqacn07epF5S20R55r/h/wCJ3jPTYtF1iXQdK06aZDeT6fNMZmjByVUMMfh7DnGa73w74V0XwppsdjoOnxWsMeTkDLsT1LMeSfqewHQCteiuOvj6takqKSjBa2jom+77v8ilFJ3CiiiuAoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKinn2Zji2PcNGzxRu20PjHfBwMkc4PWkllfcYoFzLgN86sExnB+bGM9eKfHEIlIUscsWO5y3JOe/b26CgASPa7szs+5tyhsYTgDA46cE8+p+lPoooAKKKKACub8Wf8hfwn/wBhr/21uK6Sub8Wf8hfwn/2Gv8A21uKAOkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACuV8Vf8jj4I/wCwrP8A+kFzXVVyvir/AJHHwR/2FZ//AEguaAOqooooAKKKKACiiigAryaCCD4nfGW7mupLK90DwkoiggMSypdTTR/OWJyDtZfzRcdzTL6+8S/FPxRrGieHtXXRfDGlzi1ur23RjPdyD76I3YAjHBHBB+YNivRPC/hXSfB2hx6VoVsILdCWYk5eVj1Zm7n+gAGAAK92MY5ZTk5S/fSVkl9hStdt/wAzjpZbJu7TMvjfka4AVQFAAAwAO1LRRXhGoUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUU2SRIo2kldURAWZmOAoHUk0AOqF3keUxxfIUKszumVZSTkDkc8de2RwaD5ksuMPEkcmDuCkTLt7ckgZPfByvocmSKKOCFIoUWOONQqIgwFA4AA7CgBIokhjEcYwo6DOafRRQAUUUUAFFFFABXN+LP+Qv4T/7DX/trcV0lc34s/wCQv4T/AOw1/wC2txQB0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAZniW+u9M8K6rfabD593bWcssEeM7nVCQMd+R0rxaDW/tur6DpP/AAtW7vbHXIjNqU0U0cb20gXckaSIB5Ac5G08/Jx1r3yuO1W++Gtst3pGs3fheD7S+bq0uJbdDI47upIyfc80tn/X9f8ADD6f1/X/AA5V+Hd08eteI9FttbuNd0zTZYPs13czefIjOhMkJl/j24U88jdiu7rnvCemw6bHdLpD6WNBkZG06HTYVRYxj5yzLw5Lc5roapkhXK+Kv+Rx8Ef9hWf/ANILmtHUz4n+2n+xxpP2XAx9qMu/Pf7vFcxqv/CRf8J14L/twaYIf7Sn2fYzJu3fYbnru4xjNIZ6BRRRQAUUUUAFc/478Sf8Il4F1bWxgy2sB8kMu4GViFjyPTcy59s10FeO+KtQsvin8RtF8L6QkuoaRo9011rMyj9xkDCJnvkhl/4EcdDj0stwyr11Kov3cPek/Ja2+ey82ROVlpudl8KvDL+FPhvpdhcJtvJU+03WU2t5knzFW91BCZ/2fwrsKKK5MRXniK0q095Nt/MpKysgooorAYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRTJJVi27g3zMFG1S3J9cdB79KACWWOCPfM6ouQNzHAyTgfqRTFSSVt0/yKA6GEEMrgnhjkZzgdOnzHrwaWKN9wln4lK7WVJCU69ge/vipaACiiigAooooAKKKKACiiigArm/Fn/IX8J/8AYa/9tbiukrm/Fn/IX8J/9hr/ANtbigDpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAzfEdpe3/AIX1S00mbyL6e0ljt5c42SFSFOe3OOa8w0fV/B2gaPbaZqnw41OyvIY1SaM6AbjzHAwxEqqwkyc/NnmvYaKXV+f9fqPocF8NtOa31DX9Rs9CuPD+jX80TWWnXEYiYMqkSS+UOI9xK8cH5c45rvaKKoQVyvir/kcfBH/YVn/9ILmuqrlfFX/I4+CP+wrP/wCkFzSA6qiiigAooooA5L4o+JZfCfw31XU7Ur9qCLDBuYj53YJkY7gEt/wGpvh34RTwR4IsdHxEblVMl1JF0klbljk4JA4A9gK5HxkT43+MGieEI3L6bouNV1RVQEGQf6pGJ9QRx3Eh9OPVa9jEXw+Bp0Os/ffptBfm/wDt5Ga1k2FFFFeOaBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFQSSNMGjtiRuRwLhdrLG4IGCM5JyTxjHynOOMgEkkmxkUKxMhKghcheCcn24/UU2GEp88pDTMqiRlBCsR6KScdT/iackUcbSNHGqNK26QqoBdsAZPqcAD6AU+gAooooAKKKKACiiigAooooAKKKKACub8Wf8hfwn/2Gv8A21uK6Sub8Wf8hfwn/wBhr/21uKAOkooooAKKKKACiiigAooooAKKKKACiiigAoopGYKpZiAAMkntQAtFcDF8X9HuLi8FppOtXFtbWrXaXUdn8l1EsiozxDdudQWznA4Bxmu2sL621PTre/sJVmtrmJZYpF6OrDIP5GjpcOtixRRRQAUUUUAFFFFABXK+Kv8AkcfBH/YVn/8ASC5rqq5XxV/yOPgj/sKz/wDpBc0AdVRRRQAVR1rVrbQdDvdWv932aygaaTYMsQozgD1PQVerzj403t5N4WtPC+kwrJfeJLpbON3k2LGAQzMeORgY+hJ5xiuzA4dYnEwpPZvXyW7fyV2TJ2jcf8GNHuIfCc3iXVwzav4kna+uXdcHYSfLUf7O07h7PjsK9Eqvp9mmnaZa2UP+rtoUhT6KoA/lViljcQ8TiJ1n1enkui+SsgiuVWCiiiuQoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACikJ2qSegGeBmoF3XO1zlYflkjKsys3HRlwMD2/lQACQ3ag28uIWCus8Tq275uVwQRjAxn3OMHmp1VUGEUKMk4AxyTk0tFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXN+LP+Qv4T/wCw1/7a3FdJXN+LP+Qv4T/7DX/trcUAdJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABUN4kUtjPHcHbE8bK5zjCkc/pU1Ynizw9ofiPQpYPEunx39pADOEccqVU8j3xmon8LKj8SPLdO0Dx1ZCxvtDvPDt3pNvorWFnqs0kiEWrFXWV4gvLhVHAODXqXgu2sLPwNo1vo919ssY7KJYLnBHnLtGGwemeuK+e9P8IyXFvZR6Z8PfCsv2nSTqdol5dXDzzQqQMMRhTJ8ykjgc9e1fQ3g+5jvPBWjXEC2yRy2UTKlohSJQUHCKeQB0ANbdH/XWX63/Ez6r+ui/Sxs0UUVBQUUUUAFFFFABXK+Kv8AkcfBH/YVn/8ASC5rqq5XxV/yOPgj/sKz/wDpBc0AdVRRRQAV5trgOsftDeG7EKGj0XS7jUHywIzIfKAx6ghD+Ir0mvNfh7HLrXxL8b+JroACG9/sa2UY+VYfv+/J2H8/w9XL/chWrv7MGl6y938myJ62R6VRRRXlFhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUyaQQwvIVZgiliqKWY4HQAdT7Ukk2zhEMr5XKIRuAJxu5I4HJ/A4yeKbHABIJZtkky71STYAVRmztH5Ln12g0AL5LPNvmYHY+6IJlcDbjDc4bkt7dOMjNS0UUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXN+LP+Qv4T/7DX/trcV0lc34s/wCQv4T/AOw1/wC2txQB0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFRXTbLOZjH5uI2Pl5xv46c+tS0jKGUqwBUjBBHWlJXTQ1o7nimh2vg3X/BekTWvjKbw1fWolCRDV4mnskkwHtTvAOwbRjIyMDBr1zQLGw0zw7p9jozrJYW9ukdu6uHDoBwdw65HOe9Z58C+Dt+0+FtD3Yzj+zoc/wDoNblvbw2ltHb2kMcEEShI4o1CqijgAAcAe1VfcnqSUUUUhmb4j1STRPC+p6pDD9oksrSWdYv75VSQP0rgV1Xxfqsvh3QrfxNaWlxqdhLqU+r29kjh1DLiGFGJU4D8scnAzXp7KGUqwBUjBBHWuCvvgp4KvrhZFsbq0VJDKsNpfzRRK56lUDbVPP8ACBSW+v8AW/8AwPut1H0/r+u/336F7wVqmsNrOu+H9f1GHVp9IaApfxQiJpFlUttdF+UOu3t1BHFdhXN+EdJsPD7ajo2j6BJpdlbSqyXDvvF6zLln3ElmI6EtzXSVTEFcr4q/5HHwR/2FZ/8A0gua0dT1nVLK9MNl4ZvtRiABE8NxbopPph5Fbj6Vy+q6rqV/468Fx3/h680tF1KdhLPPA4Y/Ybn5cRuxz35GOKQHoNFFFAFbUb6HS9Lur+6JEFrC80hAyQqqWP6CuF+CVpdL8PW1bUWJu9dvp9TmBXbgu23j2IQMP96tn4n6hHpnws8RzzHCtYSwDnHzSDy1/VhVzwLaNY/D3w/bSLski023V19G8tc/rmvVj7mWya+3NL5RTf5tX+RG8zeoooryiwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAqJpwZfLh2SOrASqHGYwR1IpDI0rmOEZVWKSsSVK/LkbeOeo7/yxUkaeXGqZZtoAyxyT9TQA2GHylG5jLJtCtK4UMwHrgAdz2qSiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACub8Wf8hfwn/2Gv/bW4rpK5vxZ/wAhfwn/ANhr/wBtbigDpKKKKACiiigAooooAKKKKACiiigAooooAKiuvO+xzfZcef5beXnpuxx+tS02UI0LiU4QqdxJxx35qZaxY1ufM9hqPgq11N08SXN0mpXehSxayszy/a5NQE0bBQOu7cuVC8YAr6A8G/2kPBGjf29v/tL7FF9p8z72/aM7vf1968m/tGSy1QD4Q6tqniiWJtn2W7tBeWcX+yLxyhjGPR3+le1abJeS6XayapBHb3rRKbiKJ96o+PmAPcA960Xw/wBeb0+/8iX8X9eS/Qs0UUVIzN8R3t3pvhfVL7TYPtF5bWkssEWM73VSVGO/IrzjRtD0fxFo1tqt78UNcurmeJZJXtNbFtGjEZIESYCYPGDyO9es1zd/8OvBmp3rXd/4W0me4c7nlezTc59Scc/jS6j6GT8OtTmn1LX9Kj12TxDpmmywraajKyu5LqS8TSKAJChC89fmweld1Vex0+z0uzS0020gs7aPhIbeMRov0UcCrFUxBXK+Kv8AkcfBH/YVn/8ASC5rqq5XxV/yOPgj/sKz/wDpBc0gOqooooA8z+MpOqR+GfCijI1zVY1m5P8AqY8F/wD0JT+FemAAAADAHQV514pk+2fHXwPZIy/6Hb3t3Iu7nDR7F4+q9T716LXq4x8mFw9Pycvm5NflFER+JsKKKK8osKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiikLBcbiBk4GT1NAC1XYG8Vl+ZbdlkjkUho5Cc7cq2QQOG5HXIIPqCM3ShrmMCNgjiCVAWR1bdkkEjOdvToR1qxQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFc34s/5C/hP/sNf+2txXSVzfiz/AJC/hP8A7DX/ALa3FAHSUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVzni3UE0k2N/e+KLPQtOjaRbiK7SPbeZQ7UDORtII3YGc4xXR1i+ILDUNSmsraC10m601mc30eoIzNjadhjAGM7uue3Tmple2hUd9TyCx16+/sOG6tvj5olrAYBIlodGsUkjGM7PL8zIbtt9a9i8J376p4P0m+kupLx7mzika4lgELSkqDuMYJCk9cAkCvIZbbxP4e0y3+0Q/CGys0f7LDJcNOAWXjZuYcsMc859a9q0n7WdGs/7T+y/bPJTz/sefJ3452Z5256Z7VppZ2M9bot0UUVJQUUUUAFFFFABXK+Kv+Rx8Ef9hWf/ANILmuqrlfFX/I4+CP8AsKz/APpBc0AdVRRRQB5vYN9t/aS1WQ/MNP0CO3HH3S8of+p/OvSK80+G8v8AbXxG8e+IEKvA97FYQyIPlIhQqcHPOflP6969Lr1c0XLWjT/lhBfPlTf4siG1woooryiwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooqKaYpmOEK9w0bPGjkqrYx1YA45I7H6GgBZZkiKqWXzHz5aFgC5AzgU1It5Ek+WJIZY3CkRHGOCB9ecmnpHsZzvZt7bsMc7eAMD24p9ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFc34s/5C/hP/ALDX/trcV0lc34s/5C/hP/sNf+2txQB0lFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFRXUTzWc0UT+XI8bKr/3SRgGpaiuvO+xzfZcef5beXnpuxx+tTO3K7lR3R4jpPhLWLaO3GseDoJE0HSHsrPTBcQP/aN3KwElwOcBSBklueTXrPg7SrrQ/BWj6XqDiS6s7OKGVgcjcqgEA9wOleLWKfCl/B7TeLZh/wAJd5ZN81xJINRW877Bndnd93bxjFe1eDjqbeCtGOvb/wC0jZRfafM+9v2jO739fetNbP5fq9Pvf4GfVfP9P6+82aKKKkoKKKKACiiigArlfFX/ACOPgj/sKz/+kFzXVVyvir/kcfBH/YVn/wDSC5oA6qkdtkbN12gmlqnq8/2bRL6cnHlW8j59MKTVRjzSSA4n4F2qW3we0h1RRJcNNLKw6uxmcAn32hR+FehVw/wZj8r4P6Ap7wu3fvK57/Wu4rvzWXNj67/vy/NkQ+BBRRRXnFhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFBOBk8CoS0skuIx5ao43M6giRcfw4PHJHJ9OnegAkkdpDFBxIuxiXRtpUtyAehOAeM8ZBPB5fFEsKFULEFmb5nLHJJJ5PbJ4HQDgcCiKKOCFIoUCRooVVUcADtT6ACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACub8Wf8hfwn/2Gv8A21uK6Sub8Wf8hfwn/wBhr/21uKAOkooooAKKKKACiiigAooooAKKKKACiiigAqO5lMFrLMsbSNGhYIvVsDOBUlI6CSNkcZVhgjPalK9tBq19TybT7DxXr/huHxuPGllaXMlsbqO2GmQNbW64J8ppGHmcdGbcCDmvRfC+rS694T0vVri3+zS3trHO8X9wsoJA9q5g/BP4fNHJGdAJSRtzp9tuMMfUjzOTW14b8BeG/CN1LceHtPNpLMnluxuJZMrnOMOxA/Cq01XQl33OiooopDK9/cyWenXFzBbSXckMTOlvERvlIGQozxk9Oa8v/wCFzalf+H9TvtG8DaqzWMcglaeWDFu6qT+9TzA4xjJGAcdK9Yrk/F/w/sPFMc89vczaRqssDW7X9oBukjYYKSL0kXB6Hp2IqZXs7FRtdXJvAvibUvFGhRXmraDc6S7QxOrSshS43LksgVmIX/e55FdNWJ4auLaCBvD1ubh5NDhgtpZZYCiyfuxgqTw3A5xnB4rbrSVubTYzje2u4Vyvir/kcfBH/YVn/wDSC5rR1PxVpuk3ptbuLU2kADE22k3U6YP+3HGy/rXL6r4l0/WvHXguCyj1BXTUp3JutMubZcfYbkcNLGoJ56A5qSj0GsnxWM+DNaGSM6fPyO37tq1q534hTLb/AA18SSOQB/Zdyoz6mNgP1IrowsXKvBLuvzFLZlb4XRCH4V+HFXobCNvxIyf511dc78PYxF8NPDSgY/4lVsSPcxKT/Ouiq8a+bFVH/ef5ij8KCiiiuQoKKKKACiiigAooooAKKKKACiiigAooooAKKKKACmSyxwQtLPIscaDLO7YCj1JNEsqQoGkO0FlUHHckAfqRTI0kaQSTfIV3r5aPuUjdwxyBzgD6ZI560AIUedyJAyRqxUodrLMpHfqcc+3SplUIoVAFVRgADAApaKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArm/Fn/IX8J/9hr/ANtbiukrm/Fn/IX8J/8AYa/9tbigDpKKKKACiiigAooooAKKKKACiiigAooooAKiupJIrOaSBPMkSNmRP7xA4FS0j7vLby8b8Hbu6Z96UtmNbngOkawt7Mb7VPH+oQvqHh6W7vJhfCNbC5WZD5ccfRNvK7cZIz617L4O1C+1XwTo1/qybL25sopZxt2/MVBJx2z1xXm+seD/ABZ9qn1648EfD2/vogZiyiYyyEc5+aMAt7k/jXp3hnVf7c8K6ZqhMRN5axzHyQQmWUEgZ5xn1ql8L/rv/XyJfxf15f18zUooopDM7xDqp0Lw1qWrCEzmxtZLgRA4L7FLY/SuN0/RPHmu6bbao/xDjsjdxLMtvp+kwSQxhhkANJuZhz1yM16E6LIjI6hlYYKkZBHpXDS/B3we0zPa2t9YI7FmgstSnhiJPoiuAPoAKXUfQueDNX1iXV9b8P8AiG8tdRutIaEi/tovK85JVJAdMkK428gHGCK66svw/wCGtH8LaebHQLGOzgZy7hSWZ2PVmZiWY+5JrUqmIK5XxV/yOPgj/sKz/wDpBc11Vcr4q/5HHwR/2FZ//SC5pAdVXD/Ga5Fp8H9fkK7t0KR4/wB+VFz/AOPV3Fef/HH5vhDqsQXcZZbZAPX9/H/hXo5Uk8fQT/nj+aIn8DOy0S1ax8P6daOuxoLWKMr6FUAx+lXqKK4JScpOT6lhRRRUgFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFMeVY2QMGJkbaNqFsHBPOOg46njoO4psrvxHEDucMBJt3KhxxkZB/z2pYoVjLPhfMkwZGAxuIGM/pQA2CJhiWc5naNVkCs2zIyflUnA5J56njPQYmoooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArm/Fn/IX8J/9hr/ANtbiukrm/Fn/IX8J/8AYa/9tbigDpKKKKACiiigAooooAKKKKACiiigAooooAKiu2KWU7KGZljYgK2CTjsexqWvOPiVq95o/jTwbNY6dd6qWkvFextGAaYeT6MQDjOeamWqsNb3OZ8PweGvE3hm3u9U+J2vWUlzGRdadceI4g0LdGjb5FPt0FewaNa6fY6HZWui+X/Z8MCJbeU+5fLAwuD3GO/evLftWn/9EJuP/ACy/wAa9S0Yq2iWRj086YpgTFkVVTbjH3MLwMdOOOK06MnqXaKKKkYUUUUAFFFFABXK+Kv+Rx8Ef9hWf/0gua6quV8Vf8jj4I/7Cs//AKQXNAHVV558bSX+HqWqoztdajawgKB1MgPf6V6HXnvxgy+k+GrcAZufEllFk9slj/SvTyn/AH6k+zv92pFT4WehUUUV5hYUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVXaU3KlLVyFYMPtEZVgjKcEYOec57djmhXa8VXifbbuscsc0b/M/OSCCOAQF5zk7j0xk2AMdKAGpFHHu8tFTe25toxuPqfenUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFc34s/wCQv4T/AOw1/wC2txXSVzfiz/kL+E/+w1/7a3FAHSUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVm3+g2eo63peq3PmfadLaRrfa2FzIu1sjvxWlRQAUUUUAFFFFABRRRQAUUUUAFcr4q/wCRx8Ef9hWf/wBILmuqrlfFX/I4+CP+wrP/AOkFzQB1VcB8V+T4KXGSfFlienpvrv68/wDikrSal4HjUgD/AISW2c5z/CGP+Nellf8Avcfn+TIn8J6BRRRXmlhRRRQAUUUUAFFFFABRRRQAUUUyWTyomcIz7RnagyT9KAFkcRRNIwYhQWIVSx49AOSfYVGEaaQPJkKjh4trMpI24+YcZ6ng8dD1FKsJMvmTlXdGbyyqldqnseTk+/6VLQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXN+LP+Qv4T/wCw1/7a3FdJXN+LP+Qv4T/7DX/trcUAdJRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAFXU9Rt9I0m71K+YpbWkLzSsBkhVBJ/QVxVh8TLtLqybxX4Wu/D+makyrZahLcpMhZvuLKF5iLcYzkZ4zXa6pptvrGkXem3qlre8heCUA4JVgQcfgaxtL8KyL4Pl8O+Kb9fEFs6mEPNbiMtDgBVbB5YY+9wc88Ule7/r1/QfRf16E+leI/7U8Va9ov2Xyv7HNuPO8zPm+ahb7uPlxjHU59q3K4D4deGofDXiLxNbp4jOtyl7ZGSZf39qiRsI0kP8R2kYbqQOa7+mIK5XxV/yOPgj/sKz/wDpBc1tXniDRtPuDb3+rWNrMACY57lEYA9OCc1y2u63pWp+NvBUWm6nZ3ki6nOzJb3CSED7DcjOAenNAHc1wHxMwde8CqWwf+EgiPXrhG/z+Nd/XAfEZfM8XeA0Jwv9s7sY7iMkV6WV/wC9L0l/6SyJ/Cd/RRRXmlhRRRQAUUUUAFFFFABRRUXn75tkGyTZJsm+fBj+XcOMcnleOODntggBJOFYpGPNlXYWjRhuVWbG4gkccE++04yeKI7cK4kkxLMNyiUoAwUnO3I7dPyFOhi8qJFZ2lZVCmR8bnx3OABn6DvT6ACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACub8Wf8hfwn/2Gv/bW4rpK5vxZ/wAhfwn/ANhr/wBtbigDpKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooApa1qsGh6Ffardhmgsrd55AgySqqSQPfiuMt7v4p6taxX9pF4U02CdBJHa3QuJ5UUjIDupVc49Biu7uraG9tJrW7iWaCdDHJG4yHUjBB+orh1+GFzZqsGi+OfE2nWKjbHarcRyrEvZUZ0LAAcDJNLr/X9dh9DT8H61f32o6vpniDTLOy1nT2iNzJZOXhuUkUmN1JAb+FhhuRj3rqqw/DPhOx8LQ3P2Wa7vLq8kEl1e30xlnnYDA3NxwBwAAAPStyqYitPptjcy+Zc2VvM+MbpIlY/mRXLeItPs7Txp4Je1tIIGOqTgtHGFJH2G544FdlXK+Kv+Rx8Ef9hWf/ANILmkB1Vef/ABDdv+E48ARqAS2qyN1weIz/AI16BXAeN40k+Knw93qGxc3pGf8ArgD/ADAr0ss/3i/92f8A6RIie33Hf0UUV5pYUUUUAFFFFABRRVcqbtT5g2wMCrRshVyQ3ByD049O45oAGJut0ahhEd8chO+Nwenynj35B9MVYAwAPT1NFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAVzfiz/kL+E/+w1/7a3FdJXN+LP+Qv4T/wCw1/7a3FAHSUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXK+Kv+Rx8Ef9hWf/ANILmuqrlfFX/I4+CP8AsKz/APpBc0AdVXBeNP8Akqnw9/6+L3/0nrva4Hxow/4Wt8PV5yZ749P+nevSy3+O/wDDU/8ASJET2+78zvqKKK80sKKKKACmtIiMiuyqXO1QTjccE4HrwCfwpk04j+SPY07IzRRM+3fj+nI57ZpUiw7M7s+W3KGAxH8oGFwPqecnk9uKAI1i+1Ksl1FhGWNxbzKpMTg7s5GRkHHQkArkGrFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFc34s/5C/hP/sNf+2txXSVzfiz/AJC/hP8A7DX/ALa3FAHSUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXK+Kv+Rx8Ef8AYVn/APSC5rqq5XxV/wAjj4I/7Cs//pBc0AdVXn/jBd3xl+HXTAOpHp/07rXoFcD4uP8AxeX4eD1Gp/8ApOtellv8eX+Cp/6bkRPb7vzO+ooorzSwqKWVgxihXdNt3AOGC4zg/MARn2od5GkMcPyMuxmZ4yVZSTkA5HOAfpkcGnRRLDHsjztyTyxPU56n60AEcYiDAFjuYt8zFsZ9M9B7U+iigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigArm/Fn/ACF/Cf8A2Gv/AG1uK6Sub8Wf8hfwn/2Gv/bW4oA6SiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAEZgqlmIAAySe1cTcfGLwLb3Dw/22ZzGxVntbOeeMEf7caFT+ddL4i0t9c8M6npUc5t3vbWS3WUfwFlK5/WuL0zxH4u8PaVa6TN8N7mVrSJYUk0y+gNu4UY3KGZSoOM4I4pdR9DtNC8RaR4m00X+gX8N9bFipeJvusOqkdVPscGtKuP8ABOk6tHrGu6/rmnQaTNrDw7dPhmEpjEakb3dflLtu5x2A5NdhVMQVyvir/kcfBH/YVn/9ILmuqrlfFX/I4+CP+wrP/wCkFzSA6quA8Wkf8Ln+HgOM7dTx/wB+Frv68+8XTRw/GfwI8zKiCHUMuxAC5iQDk+/H416WW/xpf4Kn/puRE9vu/M9Ad1jRnkYKqjLMxwAPWosyyS8Bokjk53BSJl29sHgZPfByp4wQSnlvOxM+VT50MPyssgJ4J4z0HTPc5zxU9eaWMiijghSGCNY4o1CoiLhVAGAAB0FPoooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACub8Wf8hfwn/wBhr/21uK6Sub8Wf8hfwn/2Gv8A21uKAOkooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigCtqN/baVplzqF9J5VtaxNNK+M7VUZJ/IVxUXjTxtqMKXmjfDtnsZlDwvfaxFbyuh6ExhW25HYnNdpqenW2r6VdadfJvtruFoZVzjKsMHn6GuKi8KfEDTIUs9J8c2ktlEoSI6hpIkmRBwAWV1DkDuQM0uv9f12H0L/gnUYdS1bXZLjT9Q0rWhLD/aFhd3HmrH8hEbREErsYA8jGSDkV2Fc74V8LzaDJf3uqatLq+raiyG6u5IliUhAQiJGvCqMnjJOSea6KqYjG1Pwlo+r3pu7+3mkmYBSUu5YxgdOFYD9K5zUfC2kaL4y8IXOnW8scralMhZ7mWTg2VyejMR2rvK5XxnLLaan4Yv0sry8itdTkeYWdu0zIrWlwgYqozjcyjPuKQHTySrEFL7sMwUYUnknA6fzqg+i2l5rFlrF/bKdRsUkjt3WRiI1fhsDgZIA6iseDxjAmJJtG8QNOyKshXSZwpIz0U5xyT79Mk4qC9+JWn2NxBbyaH4jknuAxjij0iUswXG4gY7ZH51UZSi7xdv8AggdjRXF/8LMtv+hV8Xf+CKb/AAo/4WZbf9Cr4u/8EU3+FSB2lFcX/wALMtv+hV8Xf+CKb/Cj/hZlt/0Kvi7/AMEU3+FAHaUVxf8Awsy2/wChV8Xf+CKb/Cj/AIWZbf8AQq+Lv/BFN/hQB2lFcX/wsy2/6FXxd/4Ipv8ACj/hZlt/0Kvi7/wRTf4UAdpRXF/8LMtv+hV8Xf8Agim/wqG3+K2n3QkNt4b8VSiORo32aLKdrDqpx0I9KAO6ori/+FmW3/Qq+Lv/AARTf4Uf8LMtv+hV8Xf+CKb/AAoA7SiuL/4WZbf9Cr4u/wDBFN/hR/wsy2/6FXxd/wCCKb/CgDtKK4v/AIWZbf8AQq+Lv/BFN/hR/wALMtv+hV8Xf+CKb/CgDtKK4v8A4WZbf9Cr4u/8EU3+FH/CzLb/AKFXxd/4Ipv8KAO0orhbn4rafZW7T3fhvxVDCmNzyaLKqjJwOT7mpv8AhZlt/wBCr4u/8EU3+FAHaUVxf/CzLb/oVfF3/gim/wAKP+FmW3/Qq+Lv/BFN/hQB2lFcX/wsy2/6FXxd/wCCKb/Cj/hZlt/0Kvi7/wAEU3+FAHaUVxf/AAsy2/6FXxd/4Ipv8KP+FmW3/Qq+Lv8AwRTf4UAdpRXF/wDCzLb/AKFXxd/4Ipv8KP8AhZlt/wBCr4u/8EU3+FAHaUVwv/C1tP8AtgtP+Eb8VfaDH5gi/sWXdtzjdjrjJxmpv+FmW3/Qq+Lv/BFN/hQB2lFcX/wsy2/6FXxd/wCCKb/Cj/hZlt/0Kvi7/wAEU3+FAHaUVxf/AAsy2/6FXxd/4Ipv8KP+FmW3/Qq+Lv8AwRTf4UAdpRXF/wDCzLb/AKFXxd/4Ipv8KP8AhZlt/wBCr4u/8EU3+FAHaUVxf/CzLb/oVfF3/gim/wAKP+FmW3/Qq+Lv/BFN/hQB2lFcLbfFbT7yATWvhvxVNESyh49FlYEgkEZHoQR+FTf8LMtv+hV8Xf8Agim/woA7SiuL/wCFmW3/AEKvi7/wRTf4Uf8ACzLb/oVfF3/gim/woA7SiuL/AOFmW3/Qq+Lv/BFN/hR/wsy2/wChV8Xf+CKb/CgDtKK4v/hZlt/0Kvi7/wAEU3+FH/CzLb/oVfF3/gim/wAKAO0ori/+FmW3/Qq+Lv8AwRTf4Ux/ilp8LRC58O+KLdZZUiV5tFlVS7HCjJHUkgUAdvXN+LP+Qv4T/wCw1/7a3FJ/wm1t/wBATxB/4KZv8KztQ1h/EGv+G4rLR9YiFtqZuJpbmwkhSNBbTLkswA+86jHvQB21FFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFc3q//JRPDf8A17Xv8oq6SontYJLqK5khRp4QyxyFcsgbG4A9s4H5UAS0UUUAFFFFABRRRQAUUUUAFc34L/1Ot/8AYau//Q66Sore1gtRILaFIhJI0r7Fxuc8lj7n1oAlooooAKKKKACiiigAooooA5v4hf8AIiah/wBsv/RqV0lRXVrBe27W93Ck8L43RyLlTg5HH1FS0AFFFFABRRRQAUUUUAFFFFAHNv8A8lUi/wCwK/8A6PWukqL7LAbwXfkp9oEZiEu35tmc7c+mRnFS0AFFFFABRRRQAUUUUAFFFFAHN/D/AP5E2D/r5uv/AEpkrpKitrWCygENpCkMQZmCRrgAsSxOPckn8aloAKKKKACiiigAooooAK5vxv8A8g3S/wDsNWH/AKUJXSVFcWsF2iJdQpKqSLKodc7XUhlYe4IBBoAlooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKK8kttAg8eS+M9Y1ie6+2WOoT2OmSRXLx/YVhQbWQKQAxYlie9dr4H1641r4ZaRrd989zNYLLMQPvOF5P4kZpXXLzPsn96uvyHZ81l5r7jpqK8J+wGP4NJ8S/tN1/wlGRqTXn2h+VM3+p2Z2+XsO3bjFe6RP5kKP03KDVWa0e5N+w6iiikMKKKKACiiuT+KGs3mg/DXWL/TJTDdiJYopR1jaR1TcPcbs/hSY1qzrKK8uuNAtPh74w8ISaA9zGmqXLafqKSXDyC6zEzrIwYn5wy5yPUiu38V6DceJNFGmwanNpsUkyNcvADvlhBy8QYEFdw43Dtmn009P6++5K8/X+vuNqivMPCllYWHxcu7LwP5qaHZ2Bj1VFmeS3F3vGxV3E/vAu7djtjPNen0dE+4+rQUUUUAFFFFABRRXnniSzj8V/Fmy8M6sZJNItNJfUJLVJWRZ5WlEa79pBIUAkD1NHVL+tr/AKB0b/rseh0Vwvw2lltLvxN4daeWe20XU/Ks2mkLskLxrIse48kLuIGe2KzvitrN9qOj6v4c8O3DQPbadLeareRnm3iCMUiB/vyEfgoY9xUylaN12v8AhccVd287fjY9LorF8GsW8CaCzEknTbcknv8Au1rarSUeWTXYiL5ophRRRUlBRRRQAUUV4lHpI8R/DrxF47ubm6TX4pr24sLpLl1+yLbuwjjVQdu3EfIxzuOaTaWr2Wo0r7dXY9tornJ/EUsXwxfxLsHnLpH27Zjjd5O/H515P4bm0oR+GdavYPEtjfXlxCz+J5mzDeyv96F0L5ETE7VJQDgY9aqz53Htb8f+GJv7nN/Wh73RRRSGFFFFABRRRQAUVxfxU1C7s/B8Vtp9xJazapqFtp5niba8ayyBWKnsduRntmsq20i18C/FTQNO8PedBp2t2l0lzatO8iGSFVdZRuJw2CQT3oWv9dlcHp/XnY9Jorzr4wXPk6foUVw1xPYTaoiXmm2TsLi+j2t8iBSC+DhioIyBUHwnnjbWvFFtpsd3p+lQXEItdJ1BmFxakp87bGJKI55UZ7E8UR1v5f8AA/zCWlv67/5HplFFFABRRRQAUUUUAFFeefGW21+fwFqsmlatHpun29hNLdeXGTPOQOIw2cIh7nqenFdrohJ8P6eTyfssX/oAoWqfl/wf8gelvP8A4H+Zeoryy18P2vxC8T+MLnXpLl/7NvP7O00R3Dx/Y9kSsZECkfOWbOT6AdK6n4Z6zd+IPhroupalIZbuWDbNIersjFCx9ztz+NC1V/T8Qejt6/gdVRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAHnd54W8W6Ve+Ibfwm2lPp/iCZrgy3ksiSWMroFkYKqkSA43AZXB9q6LStDv/AA/YaFoelCzk0WztTb3jTlxO21AEKAfLycls/hXRUUdLf1pt9wPV3/rXc8r/AOFf+KT4YXwK02mf8IytwD9v81/tRtRJ5nk+Xt27v4d27GO2a9TACqAowAMCloo6B1uFFFFABRRRQAVjeLvD0fivwlqOiTSmEXkJRZQM+W4OVbHfDAGtmik1dWGnZ3OCsvDvivWvEmiX3jEaXBb6FvkiWwmeQ3c5TYJG3KuxQCSF5OT1qbxZpnj3WvCV9p+k3WkWN7PelEnSeaPFl6btjFZT0JAwMnBrt6Kb13/r+vy0EtNjivA+keKPD8cGl32leG9P0aCMhV0u5nkl3+p3xgHPJJJzXa0UU27iSsFFFFIYUUUUAFch4l8P6yvi6x8U+FhZz3sFq9lc2l7K0STwswYYdVbaysPQggmuvoo63DyOK0Lw54j0HQtWvIJNLn8S6vffbJ/OMgtY87V8sEDcQsa4Bxyar+K/hJ4d1+21q6gs3j1jUoX/AH5v7hIzMU2qzIr7cDj+E8Doa72ik0mrfIabTv8AMw/BvhuHwn4RsNIhGGghUTETPIGk2jeQXOcE5wOAPQVuUUVUm5O7JSSVkFFFFIYUUUUAFeYXPgfxZbaRrPhTRZdLGgatcTSC8mlcXFpFM26WMRhSrnltp3DrzXp9FKyHdmBJot3LFJoTpZjw02l/ZBhn+078bCOm3Zs79c1x0fgjxde6HpHhPWJdJ/sPS54Ga/gkkNxdRQsGjTyiu1GO1dx3H2r1Ciqu73/rR3X3E20t/XYKKKKQwooooAKKKKAOf8beG38VeF5bC2uFtryOWO5tJ3XKxzRuHQkemRg+xNZOlaB4j1TxpaeIvF6adanTLWS3s7WwmeYM8mPMlZmVccKAFwepya7aihaf15W/IHqcJrHhzxXqT6Dr27SB4g0W4nYWweQWs8MgK7dxUsrbQpzgjOe1W/C/h3WU8Wan4p8TfY4L2+t4rSKzsZGkSGJCWyzsqlmJY9gABXYUULQHr/XzCiiigAooooAKKKKAMPxpotx4j8D6xo1i8UdxfWkkEbTEhAzDAJIBOPwNSS2+tWei6ZbaP9geeFoY7k3TOF8oDEhTaM7uOM8etbFFC0/D8P8Ahwev4/j/AMMcBe+HPFmi6/rtz4O/sua115lmkF9NJG1nPsCGRQqtvUgA4ypyOtdR4T8PxeFfCenaHBIZUsoBGZCMb26s2O2SSfxrXooWit/WmwPV3CiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDA8dard6H4A1zVNOcR3dnZSzQuVDBWVSQcHg1y2g23i3UbXTruX4l2zm4jjme1XSrfJyAxTIbPtnFdH8R7W4vvhn4itbKCW4uJtPmSOGFC7uxU4AA5J9qoeFPh14W0vS9Jv4vDGn22qQ20TmX7KElSXYMknGQc5ojo235fqEtkl5/oOufip4ZtbiQSPfNZwz/ZpdSjsJmtI5N20qZgu3g8ZzjPeoIPG40/xV4zGv3qx6RowszBiLJXzY8kDaNzEtjA5PPFeXeIIvEWu+ANVsr2HxU+vM8m7Q7HTfIsIVEmchljAlBUZGHYsT0rq9S0e5nvfHst74a1DVLK7XTGjhi3wSShI/meFscuh5wOcjFJbX/rp/wfIb+Kx3mjeOtG1q6urVTd2F1aQ/aJrfUrSS1dYv8AnphwMrx1HTvVbSviV4d1fUba0tpLyJb1itlc3NlLDBdkc4ikZQrHjjnntmvPrXTvEWvQa/omh3+u6jo13ok0SXPiKyME0NyeFiWV0V3BGc5BA9ag0rSzqbeG9Mkg8cXF5Z3NvJcWl/8AuLWwMXO/zDDtcDGFCnLA9RVJXkl6fm7/AHWJeifz/JHsPiHxFpnhbRpNV1y4+z2UTojy7S20swUcDtkis7Q/Hmia/qTafbNd2t2IftEcN9ZyWzTRZx5ibwNy+4rE+NUhi+Gc8ggNwUvbNhCP+WmLhPl59elZep/a/iH4v06XSNM1LTrbTdPvo57vULR7b97PF5axKGALEH5iRkcDmou7N+v5X/Muyuk9P+HOjtvil4Yur6GGOe7FvcT/AGaDUXspVtJpc42LMV2k54HOD2NSav8AEnw9ouoXVrdNfSLYsFvbm3sZZYLQkAgSSKpVeCD7Z5rz+4lv9V+Elj8PoPDeqwa6iW9nL5lk628Hluu6fz8bCuFJGCSSelO8WwT2PiPX7jRrfxVomtTPvt0062a9sdWOwBXdChRScbWBIwBnJqno9NVr89v6/wCGZK1Wun6f1/W6Op8UeO20BPFN7Zah/aDadpkNzb6elizLCzh9sjSLyyNgZ6BQM55qW38dwNcadf3uoXNrA+iS38+myaW6yOEZQ0oJG4Ac4XHzAgiuY1HRPEOof8JybvS5heX/AIWtIgIoj5clwI5N8cZ6MQxxgE9RWnoUU+s+OvDOoHSdQhsV8Nz2k5vLN4tknmRgowYcE7TgHqORRZ3aX9aT/wAl/VgbVk/T/wBs/wA3+Pmdxc+KtItbLSbp7ndFrEscVkUQt5pddy8DoNoJJPQdayLb4n+GbrUIreKe68ief7NDqDWcq2ksucbFmK7Cc8DnBPQ1xHhnwfrtxrlzoepW89vpvhe0urXSLuVCFna4yI3U9/Li+XjoTWDp2gTyeEtM8K39t43n1KJ4refTMiKyj2OP3onMRTyxjcMEk8D3pqzfk7fc/wCr/MTul6fn/X5HvOrapa6Jo93qeouY7WziaaZwpYqqjJOBya5eL4q+GJ7A3cMt9JG0ywWyrYTF7x2BI8lduZBgHkcDv2q/8RbW4vvhr4itbKCS4uJtOmSOGJC7uxQ4AA5J9q5XxXJq+m6N4OgtY7+w05IgmoX2nad9purPEICqqbHKAnILBSRjFT3+X43/AMiu3z/Cxa8R/FiytfAuuarocF2dS0sKklleWEyPA7cqZEwCEIyd3T3rauviFpFjZac1xFqMl7qERlh0+HT5nuio4ZjEF3KoPdgK8rk0HWL7TfiQLXT/ABFdJqOmWv2GbVoW8+72b92BtGD6JgHGOOa1dYgnn8a2fiuf/hK9P0i/0dLUS6XaOJ7eSORiUli2M4Vs5BxjIp/1+D/VC/4P/tv+bPWNC17TvEmlJqOj3Hn27MUOVKMjKcMrKwBVgeoIzWjXEfC7SzYaLqN0bPVrUahqElwP7XlDXEwwF81lCL5Zbbnacn867emxIKKKKQwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDM1/QLLxLpR07UxIYDLHL+7badyOHXn6qK06KKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigD/2Q=="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "id": "AA2HdTO2kPBi"
   },
   "source": [
    "### Curva ROC                  \n",
    "ROC: Receiver Operating Characteristics\n",
    "![roc.JPG](attachment:roc.JPG)\n",
    "\n",
    "Veremos como utilizar las funciones:\n",
    "\n",
    "-  [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve): computa la curva de ROC\n",
    "- [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score): Computa el area bajo la curva de ROC de los scores predichos.\n",
    "- [RocCurveDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay): Sirve para visualizar la curva de ROC. Con el mismo fin existe [plot_roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_roc_curve.html#sklearn.metrics.plot_roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Xz_zYixkPBi",
    "outputId": "31d3d41f-4d14-4466-b373-4694086aae38"
   },
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y, y_pred_score)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BxsPsLukPBi",
    "outputId": "53189139-c1c3-4f52-d290-ab071fb7ddbf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y, y_pred_score)\n",
    "np.set_printoptions(suppress = True) #If True, always print floating point numbers using fixed point notation, \n",
    "#                                     in which case numbers equal to zero in the current precision will print as zero. \n",
    "print('Thresholds:', thresholds)\n",
    "print('FPR:', fpr)\n",
    "print('TPR:', tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ojo! Notar que Entre los umbrales hay uno que toma valor 2. El rango del umbral es de 0 a 1, ya que es una probabilidad. Pero scikit learn suma 1 al último valor en el array de thresholds (Notar que el anteúltimo umbral es 1, y el último es 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x48Q7e9FkPBj",
    "outputId": "e1c3e75b-e22d-416a-ba30-6d31ba8fa28a"
   },
   "outputs": [],
   "source": [
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='Reg_log')\n",
    "display.plot()  \n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', linewidth=.5)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwDo6nkMkPBk"
   },
   "source": [
    "#### Repitamos el ejercicio partiendo la base en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gjh24LLkPBl"
   },
   "outputs": [],
   "source": [
    "# Entrenaremos con el 70% de la base de datos y el resto se usarán para testear \n",
    "# el modelo obtenido\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eYHGsJrkPBl"
   },
   "outputs": [],
   "source": [
    "# Estimo:\n",
    "# Ajustamos el clasificador con el metodo fit() \n",
    "log_reg = LogisticRegression(penalty=None).fit(X_train, y_train)\n",
    "y_test_pred_score = log_reg.predict_proba(X_test)[:,1]\n",
    "y_test_pred = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2n1TZMukPBl",
    "outputId": "2f4b5060-bad3-4af3-8581-0bb3f12c9d90"
   },
   "outputs": [],
   "source": [
    "# AUC y ROC\n",
    "auc = roc_auc_score(y_test, y_test_pred_score)\n",
    "print('AUC: %.4f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_score, drop_intermediate=False)  # drop_intermediate=False nos da mas thresholds ('c') para probar\n",
    "print('Thresholds:', thresholds)\n",
    "print('FPR:', fpr)\n",
    "print('TPR:', tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6QwvjRPkPBl",
    "outputId": "71ed26f4-8f71-43be-9dbc-bf1ebd019ce8"
   },
   "outputs": [],
   "source": [
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='Reg_log')\n",
    "display.plot()  \n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc3wev7MkPBm"
   },
   "source": [
    "### Análisis discriminante lineal\n",
    "\n",
    "[LinearDiscriminantAnalysis()](http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html): Es un clasificador que utiliza un límite lineal para distinguir las categorías, generado a través del ajuste de densidades condicionales de las clases y utilizando la regla de Bayes.\n",
    "\n",
    "El modelo ajusta una densidad gaussiana a cada clase, asumiendo que todas las clases comparten la misma matriz de covarianza.\n",
    "\n",
    "El modelo también se puede utilizar para reducir la dimensionalidad de la entrada proyectándola en las direcciones que aportan mayor distinción, para ello se utiliza el método `transform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvnREjWVkPBm"
   },
   "source": [
    "#### Trabajaremos con el dataset de flores iris (muy usado para ejemplos de sklearn)\n",
    "[The Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f-305aCpkPBm"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#print(type(iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKAf1OpZkPBm"
   },
   "source": [
    "The Iris dataset represents 3 kind of Iris flowers (Setosa, Versicolour and Virginica) with 4 attributes: sepal length, sepal width, petal length and petal width.\n",
    "\n",
    "Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance between classes. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels.\n",
    "\n",
    "Fuente: [Comparison of LDA and PCA 2D projection of Iris dataset](https://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html#sphx-glr-auto-examples-decomposition-plot-pca-vs-lda-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQX7irbikPBm"
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6fGlO3SkPBm",
    "outputId": "5eb99b94-3340-4f6e-f514-34a3620ee8dd"
   },
   "outputs": [],
   "source": [
    "target_names = iris.target_names\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xIIt-M5kPBm"
   },
   "outputs": [],
   "source": [
    "# Separamos la muestra en datos de entrenamiento y de validación \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                    random_state=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HI-yI241kPBn",
    "outputId": "8c4fe7f6-7c53-40ac-a07d-bc3bc2f9d5ec"
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape) #vemos lo tamaños de cada subconjunto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ds2c6bB8kPBn"
   },
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=2) # Number of components (<= min(n_classes - 1, n_features)) for dimensionality reduction.\n",
    "lda = lda.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos ver algunas partes de la formula en LDA, el vector de medias por clase de Y\n",
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.classes_ # las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.priors_ # proporciones de Y de cada clase, prob(Y=k) prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-Q5QLdakPBn"
   },
   "outputs": [],
   "source": [
    "X_r = lda.transform(X_train) # Project data to maximize class separation.\n",
    "X_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsz9f3M5kPBo",
    "outputId": "677dccc3-defc-4459-dbf0-cc5fe1bc0ef0"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "# Graficar los puntos de cada clase. \n",
    "#Se toman las coordenadas de la primera y segunda columna de X_r, indexando los valores según y, la clase.  \n",
    "plt.scatter(X_r[y_train == 0, 0], X_r[y_train == 0, 1], alpha=.8, color='navy', label='setosa')\n",
    "plt.scatter(X_r[y_train == 1, 0], X_r[y_train == 1, 1], alpha=.8, color='turquoise', label='versicolor')\n",
    "plt.scatter(X_r[y_train == 2, 0], X_r[y_train == 2, 1], alpha=.8, color='darkorange', label='virginica')\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NI3B_Q5lkPBo"
   },
   "outputs": [],
   "source": [
    "# Predecimos con el modelo de Análisis discriminante lineal sobre las X test\n",
    "y_test_pred_lda = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ld7QmD9ikPBo",
    "outputId": "dc17e3b5-999a-48aa-9bea-90822a3f00c3"
   },
   "outputs": [],
   "source": [
    "accuracy_lda = accuracy_score(y_test, y_test_pred_lda)\n",
    "print(\"La exactitud del modelo es: %.2f\" %accuracy_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_pred_lda,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQKS6N3LkPBo"
   },
   "source": [
    "### KNN\n",
    "[KNeighborsClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html?highlight=kneighborsclassifier#sklearn.neighbors.KNeighborsClassifier): Clasificador de vecinos más cercanos\n",
    "\n",
    "A continuación veremos un ejemplo de clasificación de las flores en la base de datos iris nuevamente y probaremos ajustando el parámetro k (cantidad de vecinos) para obtener el modelo con mayor precisión\n",
    "\n",
    "Fuente: [MachineLearning — KNN using scikit-learn](https://towardsdatascience.com/knn-using-scikit-learn-c6bed765be75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3SBfD-nkPBo"
   },
   "outputs": [],
   "source": [
    "# Vamos a probar con distintos tamaños de k (cantidad de vecinos)\n",
    "k_range = range(1,10)\n",
    "scores = {}      # Para guardar la accuracy en un diccionario\n",
    "scores_list = [] # Para guardar la accuracy en una lista\n",
    "for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred_knn = knn.predict(X_test)\n",
    "        scores[k] = accuracy_score(y_test, y_pred_knn)\n",
    "        scores_list.append(accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vFG6-2FkPBp",
    "outputId": "2cc1875d-7cde-4dde-e3ad-7b57c199f692"
   },
   "outputs": [],
   "source": [
    "# Observemos el diccionario con las métricas\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuHyhYbNkPBp",
    "outputId": "c9ea5eba-d527-4388-efa3-5a82d3288ef5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficamos la precisión en base a la cantidad de vecinos\n",
    "plt.plot(k_range, scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWfxBzLRkPBp"
   },
   "source": [
    "#### Los valores de K entre 3 y 10 tienen la misma precisión, que es 97,77, por lo que podemos usar cualquier valor de esos. Elegiremos K = 3 como nuestro modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cb1HRoz7kPBp",
    "outputId": "6b0abb95-f4ee-4339-c7e8-74811e4b2f57"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REZe3BpGkPBp",
    "outputId": "36e4e17f-4e9a-4a29-a76b-6a11392b0b11"
   },
   "outputs": [],
   "source": [
    "y_test_pred_knn = knn.predict(X_test)\n",
    "accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "print(\"La exactitud del modelo es: %.3f\" %accuracy_knn)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otro ejemplo del libro ISLP\n",
    "\n",
    "Vamos a usar datos del S&P Stock Market. \n",
    "Esta base contiene los retornos porcentuales del S&P 500 stock index por 1250 días, desde inicios de 2001 hasta el final de 2005. Para cada fecha, tenemos:\n",
    "- Lag1, Lag2,..., Lag5: retornos porcentuales de cada uno de los días anteriores.\n",
    "- Volume: volumen de acciones negociadas (número de acciones diarias negociadas en miles de millones de dólares)\n",
    "- Today: retorno porcentual de hoy\n",
    "- Direction: variable binaria que toma valores \"Down\" y \"Up\" indicando si el mercado tuvo un retorno positivo o negativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos de Smarket.\n",
    "smarket = load_data('Smarket')\n",
    "smarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smarket.head(5))\n",
    "print('\\nColumnas:\\n', smarket.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarket.corr(numeric_only=True) # con la opcion numeric_only=True hacemo que no tenga en cuenta Direction (string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarket.plot(y='Volume', linewidth=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smarket['Direction'].value_counts())\n",
    "\n",
    "print(smarket.groupby('Direction').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar el modelo de **regresión logística** para predicir 'Direction' usando los lags 1 a 5 y Volume. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = smarket['Direction']\n",
    "y = y.replace('Up', 1)\n",
    "y = y.replace('Down', 0)\n",
    " \n",
    "X = smarket[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.Logit(y.astype(float),X.astype(float))\n",
    "result = logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El signo negativo del coeficiente Lag1 indicaría que si el mercado ayer tuvo un retorno positvo es menos probable que hoy lo tenga. Sin embargo, los pvalores son altos, por los que no hay evidencia de una asociación fuerte entre las variables y el output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = result.predict(X) \n",
    "# Usamos todos los datos para estimar el modelo. Probabilidad del que índice S&P suba, para cada uno de los días\n",
    "\n",
    "# Clasificador de Bayes\n",
    "y_new = np.where(y_new>0.5, 1, y_new)\n",
    "y_new = np.where(y_new<=0.5, 0, y_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y, y_new) #Python pone en las filas las Y y en las columnas las Y hat (y predichas)\n",
    "\n",
    "print('Confusion Matrix:\\n', conf_mat) \n",
    "print('Accuracy Score:',accuracy_score(y, y_new)) # Cantidad de (vp+vn) sobre total\n",
    "# Acá, la matriz de confusión tiene en las filas los valores ciertos y en las columnas los valores predichos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y, y_new) #Area under curve\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(y, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='Reg_log')\n",
    "display.plot()  \n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primera vista, pareciera que la regresión logística funciona apenas mejor que adivinar al azar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos pero partiendo la base entre train y test:\n",
    "train = smarket[smarket.Year < 2005]\n",
    "test = smarket[smarket.Year >= 2005]\n",
    "    \n",
    "ytrain = train['Direction']\n",
    "ytrain = ytrain.replace('Up', 1)\n",
    "ytrain = ytrain.replace('Down', 0) \n",
    "\n",
    "ytest = test['Direction']\n",
    "ytest = ytest.replace('Up', 1)\n",
    "ytest = ytest.replace('Down', 0)\n",
    "\n",
    "Xtrain = train[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "Xtrain = sm.add_constant(Xtrain) \n",
    "\n",
    "Xtest = test[['Lag1', 'Lag2', 'Lag3', 'Lag4', 'Lag5', 'Volume']]\n",
    "Xtest = sm.add_constant(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística\n",
    "logit_model = sm.Logit(ytrain.astype(float),Xtrain.astype(float))\n",
    "results = logit_model.fit()\n",
    "print(results.summary2())\n",
    "\n",
    "# Probabilidades predichas\n",
    "y_pred = results.predict(Xtest)\n",
    "\n",
    "# Clasificador de Bayes\n",
    "y_pred=np.where(y_pred>0.5, 1, y_pred)\n",
    "y_pred=np.where(y_pred<=0.5, 0, y_pred)\n",
    "\n",
    "# Matriz de confusión\n",
    "conf_mat = confusion_matrix(ytest, y_pred) \n",
    "\n",
    "print('Confusion Matrix:\\n', conf_mat) \n",
    "print('Accuracy Score:',accuracy_score(ytest, y_pred)) # Cantidad de (vp+vn) sobre total\n",
    "# Recordar: acá la matriz de confusión tiene en las filas los valores ciertos y en las columnas los valores predichos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También vamos a usar LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "lda = LDA()\n",
    "lda.fit(Xtrain, ytrain)\n",
    "results_lda = lda.predict(Xtest)\n",
    "\n",
    "# Probabilidades\n",
    "y_pred_lda = pd.Series(results_lda.tolist())\n",
    "\n",
    "# Matriz de resultados\n",
    "conf_mat2 = confusion_matrix(ytest, y_pred_lda)\n",
    "print(conf_mat2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC y ROC\n",
    "auc = roc_auc_score(ytest, y_pred_lda)\n",
    "print('AUC LDA: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_lda)\n",
    "\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='LDA')\n",
    "display.plot()  \n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lda = roc_auc_score(ytest, y_pred_lda)\n",
    "print('AUC LDA: %.2f' % auc_lda)\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_lda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis discriminantes Cuadrático\n",
    "Seguimos el ejemplo de predecir las subas (*Up*) y bajas (*Down*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QDA() \n",
    "qda.fit(Xtrain, ytrain)\n",
    "results_qda = qda.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades\n",
    "y_pred_qda = pd.Series(results_qda.tolist())\n",
    "\n",
    "# Matriz de resultados\n",
    "conf_mat3 = confusion_matrix(ytest, y_pred_qda)\n",
    "print(conf_mat3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC y ROC\n",
    "auc = roc_auc_score(ytest, y_pred_qda)\n",
    "print('AUC QDA: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_qda)\n",
    "\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='QDA')\n",
    "display.plot()  \n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "También podemos hacer la predicción de $Pr(Y=k|X)$ y la regla de Bayes, levantando el supuesto de normalidad de $X|Y$, pero haciendo el supuesto de independencia de $X$. Implementamos la funcion [GaussianNB()](https://scikit-learn.org/dev/modules/generated/sklearn.naive_bayes.GaussianNB.html), para el modelo de clasificador de Naive Bayes, pero también podriamos estimar las densidades con metodo de Kernels.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB() \n",
    "NB.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb= NB.predict(Xtest) \n",
    "\n",
    "# Matriz de resultados\n",
    "conf_mat4 = confusion_matrix(ytest, y_pred_nb)\n",
    "print(conf_mat4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC y ROC\n",
    "auc = roc_auc_score(ytest, y_pred_nb)\n",
    "print('AUC QDA: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(ytest, y_pred_nb)\n",
    "\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='Naive Bayes')\n",
    "display.plot()  \n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
